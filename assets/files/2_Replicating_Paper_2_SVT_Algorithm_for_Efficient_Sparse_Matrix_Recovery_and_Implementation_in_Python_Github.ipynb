{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnumXGT1CqK6"
      },
      "source": [
        "#  **Replicating Paper 2: SVT Algorithm for Efficient Sparse Matrix Recovery and Implementation in Python**\n",
        "\n",
        "## **Background**\n",
        "**Matrix completion** is a critical problem in fields such as machine learning, computer vision, and control systems. It involves recovering a large matrix from a small subset of its entries, assuming the matrix has low rank. For example, in recommendation systems like Netflix, the user ratings matrix is often assumed to be low-rank because users' preferences are influenced by a limited number of factors.\n",
        "\n",
        "The SVT algorithm offers a computationally efficient method for solving the nuclear norm minimization problem, which is a convex relaxation of the rank minimization problem. The algorithm performs iterative **soft-thresholding operations** on the singular values of matrices, utilizing their sparsity and low-rank properties to reduce computational costs and storage requirements.\n",
        "\n",
        "## **Objective**\n",
        "The objective of this notebook is to **implement the Singular Value Thresholding (SVT) algorithm for matrix completion** as outlined in the paper [**A Singular Value Thresholding Algorithm for Matrix Completion by Jian-Feng Cai, Emmanuel J. Candes, and Zuowei Shen**](https://arxiv.org/abs/0810.3286). The implementation will be evaluated using the **GoodBooks dataset**, which contains ratings for 1,000 books by 6,248 users. The goal is to showcase the algorithm's ability to recover low-rank matrices from a sparse subset of their entries.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Optimization Problem**\n",
        "\n",
        "$$\\text{min} \\text({ Rank(Z)})  \\underset{\\text{Convex  Relaxation}}{=}\n",
        "  \\text{min} \\quad \\|Z\\|_*$$  \n",
        "\n",
        "$$\\text{subject to} \\quad P_\\Omega(X) = P_\\Omega(M)$$\n",
        "\n",
        "\n",
        "$$\n",
        "P_\\Omega(X)_{i,j}=\\left\\{\\begin{array}{ll}X_{i,j}&\\text{if}(i,j)\\text{is observed}\\\\0&\\text{if}(i,j)\\text{is missing}\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "\n",
        "## **Methodology**\n",
        "\n",
        "1. **Matrix Generation**:\n",
        "   - Import the sparse GoodBooks rating matrix of size 6248 users by 1000 books, denoted as $M$. Approximately **98.4% of the elements** in $M$ are zeros, while the remaining **1.6%** have values ranging from 1 to 5.\n",
        "   - From the **99,831 non-zero elements**, randomly select 80% to form the training matrix $X$. The remaining 20% will be used as the validation matrix to calculate the relative error. The distribution of zeros and non-zero elements in the $X$ matrix and the validation matrix is noted.\n",
        "\n",
        "2. **SVT Algorithm Implementation**:\n",
        "   - Initialize parameters and matrices: Set the threshold $\\tau$ to 4600 and the step size $\\delta$ to 1.26. Initialize $Y^0$ as a random matrix of the same dimensions as $M$.\n",
        "   - Iteratively update matrices $X^k$ and $Y^k$ using the SVT update rules:\n",
        "\n",
        "     $$\n",
        "     X^k = \\text{shrink}(Y^{k-1}, \\tau)\n",
        "     $$\n",
        "\n",
        "     $$\n",
        "     Y^k = Y^{k-1} + \\delta_k P_\\Omega(M - X^k)\n",
        "     $$\n",
        "\n",
        "   - Implement the `shrink` function to perform **soft-thresholding** on the singular values of the matrix.\n",
        "\n",
        "3. **Matrix Completion**:\n",
        "   - Perform matrix completion on the training matrix $X$ using the predefined $\\tau$ and $\\delta$ values over **150 iterations**. The goal is to estimate **98.72% of the zero elements** (including those from both the original matrix and the validation matrix) based on the **1.228% non-zero elements** in the training matrix. Detailed results will be provided in the following sections.\n",
        "\n",
        "4. **Convergence and Stopping Criterion**:\n",
        "   - The iterations will terminate after 150 iterations.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - Compare the recovered matrix $X^k$ with the validation matrix $X_{\\text{validation}}$ using relative error metrics.\n",
        "   - Provide **plots and tables** showing the performance of the SVT algorithm.\n",
        "\n",
        "   - Calculate the relative errors for each iteration using the formula:\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{Relative Error} = \\frac{\\|X_{\\text{validation}} - X^K_{\\text{validation}}\\|_F^2}{\\|X_{\\text{validation}}\\|_F^2}\n",
        "$$\n",
        "\n",
        "## Results\n",
        "\n",
        "- **Performance Visualization**: The performance of the SVT algorithm is illustrated through a series of plots and tables. These visualizations include:\n",
        "  - **Convergence Plots**: Graphs that track the relative error over the iterations, demonstrating how the algorithm converges towards a solution.\n",
        "  - **Error Trends**: Detailed plots showing the reduction in relative error with each iteration, highlighting the algorithm's effectiveness in minimizing error over time.\n",
        "\n",
        "- **Convergence Behavior**: The algorithm's convergence was analyzed, revealing a consistent decrease in relative error as the number of iterations increased. This behavior confirms that the SVT algorithm efficiently narrows the gap between the recovered matrix and the true matrix.\n",
        "\n",
        "- **Final Results**: After **150 iterations**, the SVT algorithm achieved a final relative error of **6.75%**. This low error rate demonstrates the algorithm's proficiency in matrix completion, validating its effectiveness in recovering the underlying low-rank structure from the sparse data.\n",
        "\n",
        "Overall, the results underscore the SVT algorithm's capability to deliver accurate matrix recovery and highlight its practical applicability in handling large-scale, sparse datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxPJXWeb1dYe"
      },
      "source": [
        "## **Pseudocode: Singular Value Thresholding (SVT) Algorithm (Page 20)**\n",
        "\n",
        "**Input:** Sampled set $\\Omega$ and sampled entries $\\mathcal{P}_{\\Omega}( M)$, step size $\\delta$, tolerance $\\epsilon$, parameter $\\tau$, increment $\\ell$, and maximum iteration count $k_{\\max}$\n",
        "\n",
        "**Output:** Matrix $X^{\\mathrm{opt}}$\n",
        "\n",
        "**Description:** Recover a low-rank matrix $M$ from a subset of sampled entries\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "\n",
        "1. Set $\\mathbf{Y}^0 = k_0 \\delta \\, \\mathcal{P}_{\\Omega}(\\mathbf{M})$\n",
        "\n",
        "2. Set $r_0 = 0$.\n",
        "\n",
        "3. For $k = 1$ to $k_{\\max}$:\n",
        "  - Set $s_k = r_{k-1} + 1$.\n",
        "\n",
        "  - **Repeat:**\n",
        "  - Compute $[\\mathbf{U}^{k-1}, \\mathbf{\\Sigma}^{k-1}, \\mathbf{V}^{k-1}]_{s_k}$.\n",
        "  - Set $s_k = s_k + \\ell$.\n",
        "  - **Until $\\sigma_{s_k - \\ell}^{k-1} \\le \\tau$.**\n",
        "  \n",
        "  - Set $r_k = \\max \\{ j : \\sigma_j^{k-1} > \\tau \\}$.\n",
        "\n",
        "  - Set $\\mathbf{X}^k = \\sum_{j = 1}^{r_k} (\\sigma_j^{k-1} - \\tau) \\mathbf{u}_j^{k-1} \\mathbf{v}_j^{k-1}$.\n",
        "\n",
        "  - If $\\frac{\\|\\mathcal{P}_{\\Omega}(\\mathbf{X}^k - \\mathbf{M})\\|_F}{\\|\\mathcal{P}_{\\Omega} \\mathbf{M}\\|_F} \\le \\epsilon$, then break.\n",
        "\n",
        "  - Set $Y_{ij}^k = \\begin{cases}\n",
        "  0 & \\text{if } (i,j) \\notin \\Omega, \\\\\n",
        "  Y_{ij}^{k-1} + \\delta (M_{ij} - X_{ij}^k) & \\text{if } (i,j) \\in \\Omega\n",
        "  \\end{cases}$.\n",
        "\n",
        " **end for k**\n",
        "\n",
        "4. Set $\\mathbf{X}^{\\text{opt}} = \\mathbf{X}^k$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rIikYdEhsZ94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csc_matrix\n",
        "from scipy.linalg import svd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "DTuSyAmcdRns",
        "outputId": "e8e5270a-5262-4115-f401-ce678999a509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in 'Book-Rating': book_id       0\n",
            "user_id       0\n",
            "rating        0\n",
            "Unnamed: 3    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       book_id  user_id  rating  Unnamed: 3\n",
              "0            1      314       5        True\n",
              "1            1      439       3        True\n",
              "2            1      588       5        True\n",
              "3            1     1169       4        True\n",
              "4            1     1185       4        True\n",
              "...        ...      ...     ...         ...\n",
              "99992     1000    52503       3        True\n",
              "99993     1000    52748       4        True\n",
              "99994     1000    52994       5        True\n",
              "99995     1000    53173       4        True\n",
              "99996     1000    53366       4        True\n",
              "\n",
              "[99831 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29ef9694-0f9e-47cc-b562-5080a0e549d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>314</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>439</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>588</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1185</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99992</th>\n",
              "      <td>1000</td>\n",
              "      <td>52503</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99993</th>\n",
              "      <td>1000</td>\n",
              "      <td>52748</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99994</th>\n",
              "      <td>1000</td>\n",
              "      <td>52994</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>1000</td>\n",
              "      <td>53173</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>1000</td>\n",
              "      <td>53366</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99831 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29ef9694-0f9e-47cc-b562-5080a0e549d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29ef9694-0f9e-47cc-b562-5080a0e549d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29ef9694-0f9e-47cc-b562-5080a0e549d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7d1a5fe-82da-400f-8eef-0a3386f6d626\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7d1a5fe-82da-400f-8eef-0a3386f6d626')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7d1a5fe-82da-400f-8eef-0a3386f6d626 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8371d92f-6a08-40c8-9b54-0eee56845d73\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Book_Rating')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8371d92f-6a08-40c8-9b54-0eee56845d73 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Book_Rating');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Book_Rating",
              "summary": "{\n  \"name\": \"Book_Rating\",\n  \"rows\": 99831,\n  \"fields\": [\n    {\n      \"column\": \"book_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14911,\n        \"min\": 7,\n        \"max\": 53403,\n        \"num_unique_values\": 6248,\n        \"samples\": [\n          21257,\n          35,\n          1280\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# Read the CSV file into a DataFrame\n",
        "Book_Rating = pd.read_csv('GoodBooks_Ratings.csv', delimiter=',')\n",
        "\n",
        "# Remove duplicate entries for the same user and book, keeping the last occurrence\n",
        "Book_Rating = Book_Rating.drop_duplicates(\n",
        "    subset=['user_id', 'book_id'], keep='last')\n",
        "\n",
        "# Print the number of null values in each column of the DataFrame\n",
        "print(f\"Number of null values in 'Book-Rating': {Book_Rating.isnull().sum()}\")\n",
        "\n",
        "# Display the DataFrame to verify the preprocessing\n",
        "Book_Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4eI9rsHhPhX",
        "outputId": "e571e1fc-a419-4268-f221-e70d575fd565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse matrix shape: (6248, 1000)\n",
            "[[5 0 3 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]\n",
            " [5 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 5]\n",
            " [0 0 0 ... 0 0 4]\n",
            " [0 0 0 ... 0 0 3]]\n"
          ]
        }
      ],
      "source": [
        "# Extract arrays of user IDs, book IDs, and ratings from the DataFrame\n",
        "User_array = Book_Rating['user_id'].values\n",
        "Book_array = Book_Rating['book_id'].values\n",
        "Rating_array = Book_Rating['rating'].values\n",
        "\n",
        "# Create mappings from original user and book IDs to consecutive integer indices\n",
        "user_mapping = {user_id: index for index,\n",
        "                user_id in enumerate(Book_Rating['user_id'].unique())}\n",
        "book_mapping = {book: index for index,\n",
        "                book in enumerate(Book_Rating['book_id'].unique())}\n",
        "\n",
        "# Map the original IDs to the new integer indices\n",
        "user_indices = [user_mapping[user_id] for user_id in User_array]\n",
        "book_indices = [book_mapping[bookid] for bookid in Book_array]\n",
        "\n",
        "# Create a sparse matrix using the ratings and the user/book indices\n",
        "# Then convert the sparse matrix to a dense matrix\n",
        "Matrix_book_data = csc_matrix((Rating_array, (user_indices, book_indices)))\n",
        "Matrix_book = Matrix_book_data.toarray()\n",
        "\n",
        "# Print the shape of the dense matrix and the matrix itself to verify\n",
        "print(f\"Sparse matrix shape: {Matrix_book.shape}\")\n",
        "print(Matrix_book)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXWQoZp7XgSr",
        "outputId": "6bb4c9c5-2fbc-46a0-8d83-a13491aef9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse matrix shape: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6148169\n",
            "Percentage of zeros: 98.402\n",
            "Number of non-zeros: 99831\n",
            "Percentage of non-zeros: 1.598\n"
          ]
        }
      ],
      "source": [
        "# Print matrix details\n",
        "print(f\"Sparse matrix shape: {Matrix_book.shape}\")\n",
        "print(f\"Maximum value: {np.max(Matrix_book)}\")\n",
        "print(f\"Minimum value: {np.min(Matrix_book)}\")\n",
        "print('-' * 60)\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book == 0)}\")\n",
        "print(\n",
        "    f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book == 0) / Matrix_book.size * 100, 3)}\")\n",
        "print(f\"Number of non-zeros: {np.count_nonzero(Matrix_book != 0)}\")\n",
        "print(\n",
        "    f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book != 0) / Matrix_book.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QRTOrSXjY5eo"
      },
      "outputs": [],
      "source": [
        "# Create a mask to identify non-zero entries in the matrix\n",
        "non_missing_mask = Matrix_book != 0\n",
        "\n",
        "# Get indices of non-zero entries\n",
        "non_missing_indices = np.nonzero(non_missing_mask)\n",
        "\n",
        "# Calculate the total number of non-zero entries\n",
        "num_non_zero = len(non_missing_indices[0])\n",
        "\n",
        "# Define the number of non-zero entries for training and validation sets\n",
        "X_80 = int(num_non_zero * 0.8)  # 80% for training\n",
        "X_validation_20 = num_non_zero - X_80  # Remaining 20% for validation\n",
        "\n",
        "# Generate an array of indices for non-zero entries and shuffle them\n",
        "indices = np.arange(num_non_zero)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Split the shuffled indices into training and validation sets\n",
        "indices_X = indices[:X_80]\n",
        "indices_X_validation = indices[X_80:]\n",
        "\n",
        "# Create boolean masks for the training and validation sets\n",
        "mask_X = np.zeros_like(Matrix_book, dtype=bool)\n",
        "mask_X_validation = np.zeros_like(Matrix_book, dtype=bool)\n",
        "\n",
        "# Set True for positions in the training mask where non-zero entries are selected\n",
        "mask_X[non_missing_indices[0][indices_X],\n",
        "       non_missing_indices[1][indices_X]] = True\n",
        "\n",
        "# Set True for positions in the validation mask where non-zero entries are selected\n",
        "mask_X_validation[non_missing_indices[0][indices_X_validation],\n",
        "                  non_missing_indices[1][indices_X_validation]] = True\n",
        "\n",
        "# Create the training matrix by retaining only the entries indicated by the training mask\n",
        "Matrix_book_X = np.where(mask_X, Matrix_book, 0)\n",
        "\n",
        "# Create the validation matrix by retaining only the entries indicated by the validation mask\n",
        "Matrix_book_X_validation = np.where(mask_X_validation, Matrix_book, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcF1aYRRaf5-",
        "outputId": "063ee56b-ea78-4eb0-dd42-b72602d11466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X matrix: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6168136\n",
            "Percentage of zeros: 98.722\n",
            "Number of non-zeros: 79864\n",
            "Percentage of non-zeros: 1.278\n"
          ]
        }
      ],
      "source": [
        "# Print details of X and validation matrices\n",
        "print(f\"Shape of X matrix: {Matrix_book_X.shape}\")\n",
        "print(f\"Maximum value: {np.max(Matrix_book_X)}\")\n",
        "print(f\"Minimum value: {np.min(Matrix_book_X)}\")\n",
        "print('-' * 60)\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book_X == 0)}\")\n",
        "print(\n",
        "    f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book_X == 0) / Matrix_book_X.size * 100, 3)}\")\n",
        "print(f\"Number of non-zeros: {np.count_nonzero(Matrix_book_X != 0)}\")\n",
        "print(\n",
        "    f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book_X != 0) / Matrix_book_X.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1uMt0C8eW8w",
        "outputId": "f4a61a5d-0e7d-418f-c9f7-c159fe518d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X validation matrix: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6228033\n",
            "Percentage of zeros: 99.68\n",
            "Number of non-zeros: 19967\n",
            "Percentage of non-zeros: 0.32\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of the X validation matrix\n",
        "print(f\"Shape of X validation matrix: {Matrix_book_X_validation.shape}\")\n",
        "\n",
        "# Print the maximum value in the X validation matrix\n",
        "print(f\"Maximum value: {np.max(Matrix_book_X_validation)}\")\n",
        "\n",
        "# Print the minimum value in the X validation matrix\n",
        "print(f\"Minimum value: {np.min(Matrix_book_X_validation)}\")\n",
        "\n",
        "# Print a separator line for readability\n",
        "print('-' * 60)\n",
        "\n",
        "# Count and print the number of zeros in the X validation matrix\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book_X_validation == 0)}\")\n",
        "\n",
        "# Calculate and print the percentage of zeros in the X validation matrix\n",
        "print(\n",
        "    f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book_X_validation == 0) / Matrix_book_X_validation.size * 100, 3)}\")\n",
        "\n",
        "# Count and print the number of non-zero entries in the X validation matrix\n",
        "print(\n",
        "    f\"Number of non-zeros: {np.count_nonzero(Matrix_book_X_validation != 0)}\")\n",
        "\n",
        "# Calculate and print the percentage of non-zero entries in the X validation matrix\n",
        "print(\n",
        "    f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book_X_validation != 0) / Matrix_book_X_validation.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdbFbN0redaS",
        "outputId": "a2e21c6e-32cf-43ae-f337-49e37dc9bc7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total non-missing - non-missing X - non-missing X validation: 0\n",
            "Total non-missing - non-missing X - non-missing X validation (check Masks): 0\n"
          ]
        }
      ],
      "source": [
        "# Validate that the splits are correct by checking if the total number of non-missing entries\n",
        "# in the original matrix matches the sum of non-missing entries in the training and validation matrices\n",
        "\n",
        "# Compute the difference between the total non-missing entries in the original matrix and\n",
        "# the sum of non-missing entries in the training and validation matrices\n",
        "review_diff = np.count_nonzero(Matrix_book != 0) - np.count_nonzero(\n",
        "    Matrix_book_X != 0) - np.count_nonzero(Matrix_book_X_validation != 0)\n",
        "\n",
        "# Compute the difference using masks to ensure that the splits were done correctly\n",
        "review_diff2 = np.count_nonzero(\n",
        "    Matrix_book != 0) - np.sum(mask_X) - np.sum(mask_X_validation)\n",
        "\n",
        "# Print the difference to check if the non-missing entries were correctly distributed between\n",
        "# the training and validation matrices\n",
        "print(\n",
        "    f'Total non-missing - non-missing X - non-missing X validation: {review_diff}')\n",
        "\n",
        "# Print the difference using mask sums to double-check the correctness of the splits\n",
        "print(\n",
        "    f'Total non-missing - non-missing X - non-missing X validation (check Masks): {review_diff2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vayjtd6GfCLg",
        "outputId": "91111bbf-f037-4e6d-9933-6ec7a557fd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total missing: 6168136\n",
            "Total missing - non-missing X validation - missing data: 0\n"
          ]
        }
      ],
      "source": [
        "# Compute the total number of missing entries in the training matrix (Matrix_book_X)\n",
        "m = mask_X.sum()\n",
        "\n",
        "# Create a mask for missing entries by inverting the mask_X (i.e., non-zeros become True)\n",
        "mask_missing = ~mask_X\n",
        "\n",
        "# Compute the total number of missing entries in the original matrix\n",
        "total_missing_num = np.sum(mask_missing)\n",
        "\n",
        "# Compute the difference between the total number of missing entries and the sum of non-missing\n",
        "# entries in the validation matrix and the number of zeros in the original matrix\n",
        "review_diff3 = total_missing_num - \\\n",
        "    np.sum(mask_X_validation) - np.count_nonzero(Matrix_book == 0)\n",
        "\n",
        "# Print the total number of missing entries in the original matrix\n",
        "print(f'Total missing: {total_missing_num}')\n",
        "\n",
        "# Print the difference between the total number of missing entries, non-missing entries in the\n",
        "# validation matrix, and the number of zeros in the original matrix to check if all missing data\n",
        "# has been accounted for correctly\n",
        "print(f'Total missing - non-missing X validation - missing data: {review_diff3}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LN0-HGf1Qg",
        "outputId": "68b98dda-dfdf-41cc-99e6-1dc96dff710b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Y: (6248, 1000)\n"
          ]
        }
      ],
      "source": [
        "# Initialize variables for matrix completion\n",
        "# Y = np.zeros(Matrix_book.shape)\n",
        "# tau =  5 * np.min(Matrix_book.shape)  # Page 20\n",
        "# Initialize variables for matrix completion\n",
        "Y = 5 * np.random.rand(*Matrix_book.shape)  # Random matrix between 0 and 5\n",
        "delta = 1.25 * Matrix_book.size / (~mask_X).sum()  # Calculate delta Page 17\n",
        "tau = 4600  # Set tau value\n",
        "\n",
        "print(f\"Shape of Y: {Y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFb0zGimgT3H",
        "outputId": "6942e184-6520-421e-c482-3b683b32ad29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1:\n",
            "  Relative Error: 0.7051\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 2:\n",
            "  Relative Error: 0.6655\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 3:\n",
            "  Relative Error: 0.6261\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 4:\n",
            "  Relative Error: 0.5874\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 5:\n",
            "  Relative Error: 0.5499\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 6:\n",
            "  Relative Error: 0.5141\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 7:\n",
            "  Relative Error: 0.4804\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 8:\n",
            "  Relative Error: 0.4490\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 9:\n",
            "  Relative Error: 0.4200\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 10:\n",
            "  Relative Error: 0.3935\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 11:\n",
            "  Relative Error: 0.3695\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 12:\n",
            "  Relative Error: 0.3477\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 13:\n",
            "  Relative Error: 0.3280\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 14:\n",
            "  Relative Error: 0.3104\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 15:\n",
            "  Relative Error: 0.2945\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 16:\n",
            "  Relative Error: 0.2801\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 17:\n",
            "  Relative Error: 0.2672\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 18:\n",
            "  Relative Error: 0.2554\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 19:\n",
            "  Relative Error: 0.2448\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 20:\n",
            "  Relative Error: 0.2351\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 21:\n",
            "  Relative Error: 0.2262\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 22:\n",
            "  Relative Error: 0.2181\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 23:\n",
            "  Relative Error: 0.2106\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 24:\n",
            "  Relative Error: 0.2037\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 25:\n",
            "  Relative Error: 0.1973\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 26:\n",
            "  Relative Error: 0.1914\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 27:\n",
            "  Relative Error: 0.1859\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 28:\n",
            "  Relative Error: 0.1807\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 29:\n",
            "  Relative Error: 0.1759\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 30:\n",
            "  Relative Error: 0.1714\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 31:\n",
            "  Relative Error: 0.1671\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 32:\n",
            "  Relative Error: 0.1631\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 33:\n",
            "  Relative Error: 0.1594\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 34:\n",
            "  Relative Error: 0.1558\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 35:\n",
            "  Relative Error: 0.1525\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 36:\n",
            "  Relative Error: 0.1493\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 37:\n",
            "  Relative Error: 0.1463\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 38:\n",
            "  Relative Error: 0.1435\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 39:\n",
            "  Relative Error: 0.1408\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 40:\n",
            "  Relative Error: 0.1382\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 41:\n",
            "  Relative Error: 0.1358\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 42:\n",
            "  Relative Error: 0.1335\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 43:\n",
            "  Relative Error: 0.1313\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 44:\n",
            "  Relative Error: 0.1292\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 45:\n",
            "  Relative Error: 0.1272\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 46:\n",
            "  Relative Error: 0.1253\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 47:\n",
            "  Relative Error: 0.1235\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 48:\n",
            "  Relative Error: 0.1217\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 49:\n",
            "  Relative Error: 0.1201\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 50:\n",
            "  Relative Error: 0.1185\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 51:\n",
            "  Relative Error: 0.1170\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 52:\n",
            "  Relative Error: 0.1155\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 53:\n",
            "  Relative Error: 0.1141\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 54:\n",
            "  Relative Error: 0.1128\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 55:\n",
            "  Relative Error: 0.1115\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 56:\n",
            "  Relative Error: 0.1102\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 57:\n",
            "  Relative Error: 0.1090\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 58:\n",
            "  Relative Error: 0.1079\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 59:\n",
            "  Relative Error: 0.1068\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 60:\n",
            "  Relative Error: 0.1057\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 61:\n",
            "  Relative Error: 0.1047\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 62:\n",
            "  Relative Error: 0.1037\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 63:\n",
            "  Relative Error: 0.1028\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 64:\n",
            "  Relative Error: 0.1019\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 65:\n",
            "  Relative Error: 0.1010\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 66:\n",
            "  Relative Error: 0.1001\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 67:\n",
            "  Relative Error: 0.0993\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 68:\n",
            "  Relative Error: 0.0985\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 69:\n",
            "  Relative Error: 0.0977\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 70:\n",
            "  Relative Error: 0.0970\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 71:\n",
            "  Relative Error: 0.0963\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 72:\n",
            "  Relative Error: 0.0956\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 73:\n",
            "  Relative Error: 0.0949\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 74:\n",
            "  Relative Error: 0.0942\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 75:\n",
            "  Relative Error: 0.0936\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 76:\n",
            "  Relative Error: 0.0930\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 77:\n",
            "  Relative Error: 0.0924\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 78:\n",
            "  Relative Error: 0.0918\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 79:\n",
            "  Relative Error: 0.0912\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 80:\n",
            "  Relative Error: 0.0907\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 81:\n",
            "  Relative Error: 0.0902\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 82:\n",
            "  Relative Error: 0.0896\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 83:\n",
            "  Relative Error: 0.0891\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 84:\n",
            "  Relative Error: 0.0883\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 85:\n",
            "  Relative Error: 0.0875\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 86:\n",
            "  Relative Error: 0.0867\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 87:\n",
            "  Relative Error: 0.0861\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 88:\n",
            "  Relative Error: 0.0854\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 89:\n",
            "  Relative Error: 0.0848\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 90:\n",
            "  Relative Error: 0.0843\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 91:\n",
            "  Relative Error: 0.0838\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 92:\n",
            "  Relative Error: 0.0833\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 93:\n",
            "  Relative Error: 0.0828\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 94:\n",
            "  Relative Error: 0.0823\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 95:\n",
            "  Relative Error: 0.0819\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 96:\n",
            "  Relative Error: 0.0815\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 97:\n",
            "  Relative Error: 0.0810\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 98:\n",
            "  Relative Error: 0.0806\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 99:\n",
            "  Relative Error: 0.0802\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 100:\n",
            "  Relative Error: 0.0799\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 101:\n",
            "  Relative Error: 0.0795\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 102:\n",
            "  Relative Error: 0.0791\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 103:\n",
            "  Relative Error: 0.0788\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 104:\n",
            "  Relative Error: 0.0784\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 105:\n",
            "  Relative Error: 0.0781\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 106:\n",
            "  Relative Error: 0.0778\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 107:\n",
            "  Relative Error: 0.0774\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 108:\n",
            "  Relative Error: 0.0771\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 109:\n",
            "  Relative Error: 0.0768\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 110:\n",
            "  Relative Error: 0.0765\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 111:\n",
            "  Relative Error: 0.0762\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 112:\n",
            "  Relative Error: 0.0759\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 113:\n",
            "  Relative Error: 0.0757\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 114:\n",
            "  Relative Error: 0.0754\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 115:\n",
            "  Relative Error: 0.0751\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 116:\n",
            "  Relative Error: 0.0749\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 117:\n",
            "  Relative Error: 0.0746\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 118:\n",
            "  Relative Error: 0.0744\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 119:\n",
            "  Relative Error: 0.0740\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 120:\n",
            "  Relative Error: 0.0736\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 121:\n",
            "  Relative Error: 0.0733\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 122:\n",
            "  Relative Error: 0.0730\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 123:\n",
            "  Relative Error: 0.0727\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 124:\n",
            "  Relative Error: 0.0724\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 125:\n",
            "  Relative Error: 0.0722\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 126:\n",
            "  Relative Error: 0.0719\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 127:\n",
            "  Relative Error: 0.0717\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 128:\n",
            "  Relative Error: 0.0714\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 129:\n",
            "  Relative Error: 0.0712\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 130:\n",
            "  Relative Error: 0.0710\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 131:\n",
            "  Relative Error: 0.0708\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 132:\n",
            "  Relative Error: 0.0706\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 133:\n",
            "  Relative Error: 0.0704\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 134:\n",
            "  Relative Error: 0.0702\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 135:\n",
            "  Relative Error: 0.0700\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 136:\n",
            "  Relative Error: 0.0698\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 137:\n",
            "  Relative Error: 0.0696\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 138:\n",
            "  Relative Error: 0.0694\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 139:\n",
            "  Relative Error: 0.0693\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 140:\n",
            "  Relative Error: 0.0691\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 141:\n",
            "  Relative Error: 0.0689\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 142:\n",
            "  Relative Error: 0.0688\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 143:\n",
            "  Relative Error: 0.0686\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 144:\n",
            "  Relative Error: 0.0684\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 145:\n",
            "  Relative Error: 0.0683\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 146:\n",
            "  Relative Error: 0.0681\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 147:\n",
            "  Relative Error: 0.0680\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 148:\n",
            "  Relative Error: 0.0678\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 149:\n",
            "  Relative Error: 0.0677\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 150:\n",
            "  Relative Error: 0.0675\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize a dictionary to store the relative errors for each iteration\n",
        "RE_list = {}\n",
        "\n",
        "# Perform the SVT algorithm for 150 iterations\n",
        "for i in range(150):\n",
        "    # Compute the Singular Value Decomposition (SVD) of the current matrix Y\n",
        "    u, s, vh = svd(Y, full_matrices=False)\n",
        "\n",
        "    # Apply soft-thresholding to the singular values\n",
        "    s_t = np.maximum(s - tau, 0)\n",
        "\n",
        "    # Reconstruct the matrix Z using the thresholded singular values\n",
        "    Z = (u[:, :1000] * s_t) @ vh\n",
        "\n",
        "    # Compute the prediction error matrix P\n",
        "    P = Matrix_book_X - Z\n",
        "\n",
        "    # Set the entries corresponding to missing data in the prediction error matrix to 0\n",
        "    P[mask_missing] = 0\n",
        "\n",
        "    # Update the matrix Y using the step size delta and the prediction error matrix P\n",
        "    Y0 = Y.copy()\n",
        "    Y = Y0 + delta * P\n",
        "\n",
        "    # Compute the relative error of the reconstructed matrix Z with respect to the validation matrix\n",
        "    relative_error = np.sum((Z[mask_X_validation] - Matrix_book_X_validation[mask_X_validation])\n",
        "                            ** 2) / np.sum(Matrix_book_X_validation[mask_X_validation]**2)\n",
        "\n",
        "    # Optionally compute the Mean Squared Error (MSE) for additional evaluation\n",
        "    MSE = np.mean(\n",
        "        (Z[mask_X_validation] - Matrix_book_X_validation[mask_X_validation])**2)\n",
        "\n",
        "    # Store the relative error for the current iteration in the dictionary\n",
        "    RE_list[i] = relative_error\n",
        "\n",
        "    # Print the relative error for the current iteration\n",
        "    print(f\"Iteration {i+1}:\")\n",
        "    print(f\"  Relative Error: {relative_error:.4f}\")\n",
        "    print('-' * 60 + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYRFFsFJgf6m",
        "outputId": "c629179f-35ab-466a-875b-855fb93962a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, RE: 0.7051\n",
            "Iteration 2, RE: 0.6655\n",
            "Iteration 3, RE: 0.6261\n",
            "Iteration 4, RE: 0.5874\n",
            "Iteration 5, RE: 0.5499\n",
            "Iteration 6, RE: 0.5141\n",
            "Iteration 7, RE: 0.4804\n",
            "Iteration 8, RE: 0.4490\n",
            "Iteration 9, RE: 0.4200\n",
            "Iteration 10, RE: 0.3935\n",
            "Iteration 11, RE: 0.3695\n",
            "Iteration 12, RE: 0.3477\n",
            "Iteration 13, RE: 0.3280\n",
            "Iteration 14, RE: 0.3104\n",
            "Iteration 15, RE: 0.2945\n",
            "Iteration 16, RE: 0.2801\n",
            "Iteration 17, RE: 0.2672\n",
            "Iteration 18, RE: 0.2554\n",
            "Iteration 19, RE: 0.2448\n",
            "Iteration 20, RE: 0.2351\n",
            "Iteration 21, RE: 0.2262\n",
            "Iteration 22, RE: 0.2181\n",
            "Iteration 23, RE: 0.2106\n",
            "Iteration 24, RE: 0.2037\n",
            "Iteration 25, RE: 0.1973\n",
            "Iteration 26, RE: 0.1914\n",
            "Iteration 27, RE: 0.1859\n",
            "Iteration 28, RE: 0.1807\n",
            "Iteration 29, RE: 0.1759\n",
            "Iteration 30, RE: 0.1714\n",
            "Iteration 31, RE: 0.1671\n",
            "Iteration 32, RE: 0.1631\n",
            "Iteration 33, RE: 0.1594\n",
            "Iteration 34, RE: 0.1558\n",
            "Iteration 35, RE: 0.1525\n",
            "Iteration 36, RE: 0.1493\n",
            "Iteration 37, RE: 0.1463\n",
            "Iteration 38, RE: 0.1435\n",
            "Iteration 39, RE: 0.1408\n",
            "Iteration 40, RE: 0.1382\n",
            "Iteration 41, RE: 0.1358\n",
            "Iteration 42, RE: 0.1335\n",
            "Iteration 43, RE: 0.1313\n",
            "Iteration 44, RE: 0.1292\n",
            "Iteration 45, RE: 0.1272\n",
            "Iteration 46, RE: 0.1253\n",
            "Iteration 47, RE: 0.1235\n",
            "Iteration 48, RE: 0.1217\n",
            "Iteration 49, RE: 0.1201\n",
            "Iteration 50, RE: 0.1185\n",
            "Iteration 51, RE: 0.1170\n",
            "Iteration 52, RE: 0.1155\n",
            "Iteration 53, RE: 0.1141\n",
            "Iteration 54, RE: 0.1128\n",
            "Iteration 55, RE: 0.1115\n",
            "Iteration 56, RE: 0.1102\n",
            "Iteration 57, RE: 0.1090\n",
            "Iteration 58, RE: 0.1079\n",
            "Iteration 59, RE: 0.1068\n",
            "Iteration 60, RE: 0.1057\n",
            "Iteration 61, RE: 0.1047\n",
            "Iteration 62, RE: 0.1037\n",
            "Iteration 63, RE: 0.1028\n",
            "Iteration 64, RE: 0.1019\n",
            "Iteration 65, RE: 0.1010\n",
            "Iteration 66, RE: 0.1001\n",
            "Iteration 67, RE: 0.0993\n",
            "Iteration 68, RE: 0.0985\n",
            "Iteration 69, RE: 0.0977\n",
            "Iteration 70, RE: 0.0970\n",
            "Iteration 71, RE: 0.0963\n",
            "Iteration 72, RE: 0.0956\n",
            "Iteration 73, RE: 0.0949\n",
            "Iteration 74, RE: 0.0942\n",
            "Iteration 75, RE: 0.0936\n",
            "Iteration 76, RE: 0.0930\n",
            "Iteration 77, RE: 0.0924\n",
            "Iteration 78, RE: 0.0918\n",
            "Iteration 79, RE: 0.0912\n",
            "Iteration 80, RE: 0.0907\n",
            "Iteration 81, RE: 0.0902\n",
            "Iteration 82, RE: 0.0896\n",
            "Iteration 83, RE: 0.0891\n",
            "Iteration 84, RE: 0.0883\n",
            "Iteration 85, RE: 0.0875\n",
            "Iteration 86, RE: 0.0867\n",
            "Iteration 87, RE: 0.0861\n",
            "Iteration 88, RE: 0.0854\n",
            "Iteration 89, RE: 0.0848\n",
            "Iteration 90, RE: 0.0843\n",
            "Iteration 91, RE: 0.0838\n",
            "Iteration 92, RE: 0.0833\n",
            "Iteration 93, RE: 0.0828\n",
            "Iteration 94, RE: 0.0823\n",
            "Iteration 95, RE: 0.0819\n",
            "Iteration 96, RE: 0.0815\n",
            "Iteration 97, RE: 0.0810\n",
            "Iteration 98, RE: 0.0806\n",
            "Iteration 99, RE: 0.0802\n",
            "Iteration 100, RE: 0.0799\n",
            "Iteration 101, RE: 0.0795\n",
            "Iteration 102, RE: 0.0791\n",
            "Iteration 103, RE: 0.0788\n",
            "Iteration 104, RE: 0.0784\n",
            "Iteration 105, RE: 0.0781\n",
            "Iteration 106, RE: 0.0778\n",
            "Iteration 107, RE: 0.0774\n",
            "Iteration 108, RE: 0.0771\n",
            "Iteration 109, RE: 0.0768\n",
            "Iteration 110, RE: 0.0765\n",
            "Iteration 111, RE: 0.0762\n",
            "Iteration 112, RE: 0.0759\n",
            "Iteration 113, RE: 0.0757\n",
            "Iteration 114, RE: 0.0754\n",
            "Iteration 115, RE: 0.0751\n",
            "Iteration 116, RE: 0.0749\n",
            "Iteration 117, RE: 0.0746\n",
            "Iteration 118, RE: 0.0744\n",
            "Iteration 119, RE: 0.0740\n",
            "Iteration 120, RE: 0.0736\n",
            "Iteration 121, RE: 0.0733\n",
            "Iteration 122, RE: 0.0730\n",
            "Iteration 123, RE: 0.0727\n",
            "Iteration 124, RE: 0.0724\n",
            "Iteration 125, RE: 0.0722\n",
            "Iteration 126, RE: 0.0719\n",
            "Iteration 127, RE: 0.0717\n",
            "Iteration 128, RE: 0.0714\n",
            "Iteration 129, RE: 0.0712\n",
            "Iteration 130, RE: 0.0710\n",
            "Iteration 131, RE: 0.0708\n",
            "Iteration 132, RE: 0.0706\n",
            "Iteration 133, RE: 0.0704\n",
            "Iteration 134, RE: 0.0702\n",
            "Iteration 135, RE: 0.0700\n",
            "Iteration 136, RE: 0.0698\n",
            "Iteration 137, RE: 0.0696\n",
            "Iteration 138, RE: 0.0694\n",
            "Iteration 139, RE: 0.0693\n",
            "Iteration 140, RE: 0.0691\n",
            "Iteration 141, RE: 0.0689\n",
            "Iteration 142, RE: 0.0688\n",
            "Iteration 143, RE: 0.0686\n",
            "Iteration 144, RE: 0.0684\n",
            "Iteration 145, RE: 0.0683\n",
            "Iteration 146, RE: 0.0681\n",
            "Iteration 147, RE: 0.0680\n",
            "Iteration 148, RE: 0.0678\n",
            "Iteration 149, RE: 0.0677\n",
            "Iteration 150, RE: 0.0675\n"
          ]
        }
      ],
      "source": [
        "# Print relative errors for all iterations\n",
        "for key, value in RE_list.items():\n",
        "    print(f\"Iteration {key+1}, RE: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "WTfIqQBsiCbX",
        "outputId": "0be85627-beb6-470c-ca10-07d749987795"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract the iteration numbers and corresponding errors from the dictionary\n",
        "iterations = [i + 1 for i in RE_list.keys()]\n",
        "errors = list(RE_list.values())\n",
        "\n",
        "# Create a new figure for plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the relative error over iterations with a line plot\n",
        "plt.plot(iterations, errors, linestyle='-', color='g')  # Plot with line only\n",
        "\n",
        "# Set the x-axis ticks for better readability\n",
        "plt.xticks(ticks=range(min(iterations) - 1, max(iterations) - 1 + 30, 10))\n",
        "\n",
        "# Label the x-axis and y-axis\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Relative Error')\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title('Relative Error over Iterations')\n",
        "\n",
        "# Annotate the plot with the relative error percentage at the final iteration\n",
        "plt.annotate(f'{RE_list[149] * 100:.2f}%',\n",
        "             (140, RE_list[149] + 0.05),\n",
        "             textcoords=\"offset points\",\n",
        "             xytext=(0, 5),\n",
        "             ha='center',\n",
        "             fontsize=9,\n",
        "             color='red')\n",
        "\n",
        "# Draw an arrow indicating the final relative error point on the plot\n",
        "plt.annotate('',\n",
        "             xy=(149, RE_list[149] + 0.01),\n",
        "             xytext=(140, RE_list[149] + 0.05),\n",
        "             arrowprops=dict(facecolor='red', edgecolor='red', arrowstyle='->', linewidth=1.0))\n",
        "\n",
        "# Set the limits for the x-axis and y-axis\n",
        "plt.xlim(0, 150)\n",
        "plt.ylim(0, 0.8)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-KDMiN2H8GY"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "The implementation of the Singular Value Thresholding (SVT) algorithm successfully demonstrated its ability to recover low-rank matrices from sparse data. Based on the methodology detailed in the paper [**A Singular Value Thresholding Algorithm for Matrix Completion**](https://arxiv.org/abs/0810.3286), the following key outcomes were achieved:\n",
        "\n",
        "### Summary of Findings\n",
        "\n",
        "1. **Matrix Completion Efficiency**: The SVT algorithm effectively completed matrix recovery on the GoodBooks dataset, which had a sparse matrix with approximately **98.4%** missing values. By utilizing 80% of the non-zero elements for training and 20% for validation, the algorithm efficiently reconstructed the missing values.\n",
        "\n",
        "2. **Algorithm Performance**:\n",
        "   - **Relative Error**: The SVT algorithm achieved a relative error of **6.75%** after **150 iterations**, indicating high accuracy in approximating the original matrix with a low-rank representation.\n",
        "   - **Convergence**: The convergence behavior was demonstrated through plots showing the decrease in relative error over iterations. The algorithm exhibited steady convergence with decreasing error as iterations progressed.\n",
        "\n",
        "3. **Parameter Tuning**:\n",
        "   - **Threshold $\\tau$**: The selected threshold of $\\tau = 4600$ and step size $\\delta = 1.26$ were instrumental in achieving optimal results. These parameters influenced the soft-thresholding and update rules, impacting both convergence speed and accuracy.\n",
        "\n",
        "4. **Practical Implications**: The results underscore the SVT algorithm's potential for practical applications such as recommendation systems and collaborative filtering. Its capability to handle large, sparse matrices efficiently makes it a valuable tool in data science and machine learning.\n",
        "\n",
        "### Visual Insights\n",
        "\n",
        "- **Convergence Plots**: The provided plots illustrate the SVT algorithm's convergence, showcasing the decline in relative error over the course of the iterations.\n",
        "- **Performance Metrics**: Tables and graphs detail the accuracy of the recovered matrix and the relative errors for each iteration, validating the algorithm's effectiveness.\n",
        "\n",
        "In conclusion, the SVT algorithm proves to be a robust and efficient method for matrix completion, effectively recovering low-rank matrices from sparse data with notable accuracy. The results confirm the theoretical advantages of the SVT approach and highlight its practical applicability in real-world scenarios.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}