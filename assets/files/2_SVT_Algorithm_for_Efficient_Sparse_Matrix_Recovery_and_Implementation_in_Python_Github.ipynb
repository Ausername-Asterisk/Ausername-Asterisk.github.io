{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnumXGT1CqK6"
      },
      "source": [
        "#  **Replicating Paper 2: SVT Algorithm for Efficient Sparse Matrix Recovery and its Python Implementation**\n",
        "#### <font color=\"#9B1B30 \">**See Appendix for Details on Collaborative Filtering** </font>\n",
        "## **Background**\n",
        "**Matrix completion** is a critical problem in fields such as machine learning, computer vision, and control systems. It involves recovering a large matrix from a small subset of its entries, assuming the matrix has low rank. For example, in recommendation systems like Netflix, the user ratings matrix is often assumed to be low-rank because users' preferences are influenced by a limited number of factors.\n",
        "\n",
        "The SVT algorithm offers a computationally efficient method for solving the nuclear norm minimization problem, which is a convex relaxation of the rank minimization problem. The algorithm performs iterative **soft-thresholding operations** on the singular values of matrices, utilizing their sparsity and low-rank properties to reduce computational costs and storage requirements.\n",
        "\n",
        "## **Objective**\n",
        "The objective of this notebook is to **implement the Singular Value Thresholding (SVT) algorithm for matrix completion** as outlined in the paper [**A Singular Value Thresholding Algorithm for Matrix Completion by Jian-Feng Cai, Emmanuel J. Candes, and Zuowei Shen**](https://arxiv.org/abs/0810.3286). The implementation will be evaluated using the **GoodBooks dataset**, which contains ratings for 1,000 books by 6,248 users. The goal is to showcase the algorithm's ability to recover low-rank matrices from a sparse subset of their entries.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Optimization Problem**\n",
        "\n",
        "$$\\text{min} \\text({ Rank(Z)})  \\underset{\\text{Convex  Relaxation}}{=}\n",
        "  \\text{min} \\quad \\|Z\\|_*$$  \n",
        "\n",
        "$$\\text{subject to} \\quad P_\\Omega(X) = P_\\Omega(M)$$\n",
        "\n",
        "\n",
        "$$\n",
        "P_\\Omega(X)_{i,j}=\\left\\{\\begin{array}{ll}X_{i,j}&\\text{if}(i,j)\\text{is observed}\\\\0&\\text{if}(i,j)\\text{is missing}\\end{array}\\right.\n",
        "$$\n",
        "\n",
        "\n",
        "## **Methodology**\n",
        "\n",
        "1. **Matrix Generation**:\n",
        "   - Import the sparse GoodBooks rating matrix of size 6248 users by 1000 books, denoted as $M$. Approximately **98.4% of the elements** in $M$ are zeros, while the remaining **1.6%** have values ranging from 1 to 5.\n",
        "   - From the **99,831 non-zero elements**, randomly select 80% to form the training matrix $X$. The remaining 20% will be used as the validation matrix to calculate the relative error. The distribution of zeros and non-zero elements in the $X$ matrix and the validation matrix is noted.\n",
        "\n",
        "2. **SVT Algorithm Implementation**:\n",
        "   - Initialize parameters and matrices: Set the threshold $\\tau$ to 4600 and the step size $\\delta$ to 1.26. Initialize $Y^0$ as a random matrix of the same dimensions as $M$.\n",
        "   - Iteratively update matrices $X^k$ and $Y^k$ using the SVT update rules:\n",
        "\n",
        "     $$\n",
        "     X^k = \\text{shrink}(Y^{k-1}, \\tau)\n",
        "     $$\n",
        "\n",
        "     $$\n",
        "     Y^k = Y^{k-1} + \\delta_k P_\\Omega(M - X^k)\n",
        "     $$\n",
        "\n",
        "   - Implement the `shrink` function to perform **soft-thresholding** on the singular values of the matrix.\n",
        "\n",
        "3. **Matrix Completion**:\n",
        "   - Perform matrix completion on the training matrix $X$ using the predefined $\\tau$ and $\\delta$ values over **150 iterations**. The goal is to estimate **98.72% of the zero elements** (including those from both the original matrix and the validation matrix) based on the **1.228% non-zero elements** in the training matrix. Detailed results will be provided in the following sections.\n",
        "\n",
        "4. **Convergence and Stopping Criterion**:\n",
        "   - The iterations will terminate after 150 iterations.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - Compare the recovered matrix $X^k$ with the validation matrix $X_{\\text{validation}}$ using relative error metrics.\n",
        "   - Provide **plots and tables** showing the performance of the SVT algorithm.\n",
        "\n",
        "   - Calculate the relative errors for each iteration using the formula:\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{Relative Error} = \\frac{\\|X_{\\text{validation}} - X^K_{\\text{validation}}\\|_F^2}{\\|X_{\\text{validation}}\\|_F^2}\n",
        "$$\n",
        "\n",
        "## Results\n",
        "\n",
        "- **Performance Visualization**: The performance of the SVT algorithm is illustrated through a series of plots and tables. These visualizations include:\n",
        "  - **Convergence Plots**: Graphs that track the relative error over the iterations, demonstrating how the algorithm converges towards a solution.\n",
        "  - **Error Trends**: Detailed plots showing the reduction in relative error with each iteration, highlighting the algorithm's effectiveness in minimizing error over time.\n",
        "\n",
        "- **Convergence Behavior**: The algorithm's convergence was analyzed, revealing a consistent decrease in relative error as the number of iterations increased. This behavior confirms that the SVT algorithm efficiently narrows the gap between the recovered matrix and the true matrix.\n",
        "\n",
        "- **Final Results**: After **150 iterations**, the SVT algorithm achieved a final relative error of **6.75%**. This low error rate demonstrates the algorithm's proficiency in matrix completion, validating its effectiveness in recovering the underlying low-rank structure from the sparse data.\n",
        "\n",
        "Overall, the results underscore the SVT algorithm's capability to deliver accurate matrix recovery and highlight its practical applicability in handling large-scale, sparse datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxPJXWeb1dYe"
      },
      "source": [
        "## **Pseudocode: Singular Value Thresholding (SVT) Algorithm (Page 20)**\n",
        "\n",
        "**Input:** Sampled set $\\Omega$ and sampled entries $\\mathcal{P}_{\\Omega}( M)$, step size $\\delta$, tolerance $\\epsilon$, parameter $\\tau$, increment $\\ell$, and maximum iteration count $k_{\\max}$\n",
        "\n",
        "**Output:** Matrix $X^{\\mathrm{opt}}$\n",
        "\n",
        "**Description:** Recover a low-rank matrix $M$ from a subset of sampled entries\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "\n",
        "1. Set $\\mathbf{Y}^0 = k_0 \\delta \\, \\mathcal{P}_{\\Omega}(\\mathbf{M})$\n",
        "\n",
        "2. Set $r_0 = 0$.\n",
        "\n",
        "3. For $k = 1$ to $k_{\\max}$:\n",
        "  > Set $s_k = r_{k-1} + 1$.\n",
        "   \n",
        "  >   **Repeat:**\n",
        "  >\n",
        "  > Compute $[\\mathbf{U}^{k-1}, \\mathbf{\\Sigma}^{k-1}, \\mathbf{V}^{k-1}]_{s_k}$.\n",
        "  >\n",
        "  >Set $s_k = s_k + \\ell$.\n",
        "  >\n",
        "  > **Until $\\sigma_{s_k - \\ell}^{k-1} \\le \\tau$.**\n",
        "  \n",
        "  >Set $r_k = \\max \\{ j : \\sigma_j^{k-1} > \\tau \\}$.\n",
        "  >\n",
        "  >Set $\\mathbf{X}^k = \\sum_{j = 1}^{r_k} (\\sigma_j^{k-1} - \\tau) \\mathbf{u}_j^{k-1} \\mathbf{v}_j^{k-1}$.\n",
        "  >\n",
        "  >If $\\frac{\\|\\mathcal{P}_{\\Omega}(\\mathbf{X}^k - \\mathbf{M})\\|_F}{\\|\\mathcal{P}_{\\Omega} \\mathbf{M}\\|_F} \\le \\epsilon$, then break.\n",
        "  >\n",
        "  >Set $Y_{ij}^k = \\begin{cases}\n",
        "  0 & \\text{if } (i,j) \\notin \\Omega, \\\\\n",
        "  Y_{ij}^{k-1} + \\delta (M_{ij} - X_{ij}^k) & \\text{if } (i,j) \\in \\Omega\n",
        "  \\end{cases}$.\n",
        "  >\n",
        "  > **end for k**\n",
        "\n",
        "4. Set $\\mathbf{X}^{\\text{opt}} = \\mathbf{X}^k$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rIikYdEhsZ94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csc_matrix\n",
        "from scipy.linalg import svd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "DTuSyAmcdRns",
        "outputId": "b33249a6-ff64-4efd-887c-b9295b84ac1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in 'Book-Rating': book_id       0\n",
            "user_id       0\n",
            "rating        0\n",
            "Unnamed: 3    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       book_id  user_id  rating  Unnamed: 3\n",
              "0            1      314       5        True\n",
              "1            1      439       3        True\n",
              "2            1      588       5        True\n",
              "3            1     1169       4        True\n",
              "4            1     1185       4        True\n",
              "...        ...      ...     ...         ...\n",
              "99992     1000    52503       3        True\n",
              "99993     1000    52748       4        True\n",
              "99994     1000    52994       5        True\n",
              "99995     1000    53173       4        True\n",
              "99996     1000    53366       4        True\n",
              "\n",
              "[99831 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c73b481-fbc2-4e88-bbd1-6cc715d01eb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>314</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>439</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>588</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1185</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99992</th>\n",
              "      <td>1000</td>\n",
              "      <td>52503</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99993</th>\n",
              "      <td>1000</td>\n",
              "      <td>52748</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99994</th>\n",
              "      <td>1000</td>\n",
              "      <td>52994</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>1000</td>\n",
              "      <td>53173</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>1000</td>\n",
              "      <td>53366</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99831 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c73b481-fbc2-4e88-bbd1-6cc715d01eb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c73b481-fbc2-4e88-bbd1-6cc715d01eb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c73b481-fbc2-4e88-bbd1-6cc715d01eb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee2f6e48-55d8-40d1-824b-4dbd2a4dd0fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee2f6e48-55d8-40d1-824b-4dbd2a4dd0fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee2f6e48-55d8-40d1-824b-4dbd2a4dd0fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a01912d4-5cf2-4115-bde1-ae5d7f859b58\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Book_Rating')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a01912d4-5cf2-4115-bde1-ae5d7f859b58 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Book_Rating');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Book_Rating",
              "summary": "{\n  \"name\": \"Book_Rating\",\n  \"rows\": 99831,\n  \"fields\": [\n    {\n      \"column\": \"book_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          522,\n          738,\n          741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14911,\n        \"min\": 7,\n        \"max\": 53403,\n        \"num_unique_values\": 6248,\n        \"samples\": [\n          21257,\n          35,\n          1280\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# Read the CSV file into a DataFrame\n",
        "Book_Rating = pd.read_csv('GoodBooks_Ratings.csv', delimiter=',')\n",
        "\n",
        "# Remove duplicate entries for the same user and book, keeping the last occurrence\n",
        "Book_Rating = Book_Rating.drop_duplicates(\n",
        "    subset=['user_id', 'book_id'], keep='last')\n",
        "\n",
        "# Print the number of null values in each column of the DataFrame\n",
        "print(f\"Number of null values in 'Book-Rating': {Book_Rating.isnull().sum()}\")\n",
        "\n",
        "# Display the DataFrame to verify the preprocessing\n",
        "Book_Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4eI9rsHhPhX",
        "outputId": "91f47de3-185b-46b8-fc32-25e461999d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse matrix shape: (6248, 1000)\n",
            "[[5 0 3 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]\n",
            " [5 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 5]\n",
            " [0 0 0 ... 0 0 4]\n",
            " [0 0 0 ... 0 0 3]]\n"
          ]
        }
      ],
      "source": [
        "# Extract arrays of user IDs, book IDs, and ratings from the DataFrame\n",
        "User_array = Book_Rating['user_id'].values\n",
        "Book_array = Book_Rating['book_id'].values\n",
        "Rating_array = Book_Rating['rating'].values\n",
        "\n",
        "# Create mappings from original user and book IDs to consecutive integer indices\n",
        "user_mapping = {user_id: index for index,\n",
        "                user_id in enumerate(Book_Rating['user_id'].unique())}\n",
        "book_mapping = {book: index for index,\n",
        "                book in enumerate(Book_Rating['book_id'].unique())}\n",
        "\n",
        "# Map the original IDs to the new integer indices\n",
        "user_indices = [user_mapping[user_id] for user_id in User_array]\n",
        "book_indices = [book_mapping[bookid] for bookid in Book_array]\n",
        "\n",
        "# Create a sparse matrix using the ratings and the user/book indices\n",
        "# Then convert the sparse matrix to a dense matrix\n",
        "Matrix_book_data = csc_matrix((Rating_array, (user_indices, book_indices)))\n",
        "Matrix_book = Matrix_book_data.toarray()\n",
        "\n",
        "# Print the shape of the dense matrix and the matrix itself to verify\n",
        "print(f\"Sparse matrix shape: {Matrix_book.shape}\")\n",
        "print(Matrix_book)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXWQoZp7XgSr",
        "outputId": "6441330e-1574-4bf5-b5ef-78b70edf5b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse matrix shape: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6148169\n",
            "Percentage of zeros: 98.402\n",
            "Number of non-zeros: 99831\n",
            "Percentage of non-zeros: 1.598\n"
          ]
        }
      ],
      "source": [
        "# Print matrix details\n",
        "print(f\"Sparse matrix shape: {Matrix_book.shape}\")\n",
        "print(f\"Maximum value: {np.max(Matrix_book)}\")\n",
        "print(f\"Minimum value: {np.min(Matrix_book)}\")\n",
        "print('-' * 60)\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book == 0)}\")\n",
        "print(f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book == 0) / Matrix_book.size * 100, 3)}\")\n",
        "print(f\"Number of non-zeros: {np.count_nonzero(Matrix_book != 0)}\")\n",
        "print( f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book != 0) / Matrix_book.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QRTOrSXjY5eo"
      },
      "outputs": [],
      "source": [
        "# Create a mask to identify non-zero entries in the matrix\n",
        "non_missing_mask = Matrix_book != 0\n",
        "\n",
        "# Get indices of non-zero entries\n",
        "non_missing_indices = np.nonzero(non_missing_mask)\n",
        "\n",
        "# Calculate the total number of non-zero entries\n",
        "num_non_zero = len(non_missing_indices[0])\n",
        "\n",
        "# Define the number of non-zero entries for training and validation sets\n",
        "X_80 = int(num_non_zero * 0.8)  # 80% for training\n",
        "X_validation_20 = num_non_zero - X_80  # Remaining 20% for validation\n",
        "\n",
        "# Generate an array of indices for non-zero entries and shuffle them\n",
        "indices = np.arange(num_non_zero)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Split the shuffled indices into training and validation sets\n",
        "indices_X = indices[:X_80]\n",
        "indices_X_validation = indices[X_80:]\n",
        "\n",
        "# Create boolean masks for the training and validation sets\n",
        "mask_X = np.zeros_like(Matrix_book, dtype=bool)\n",
        "mask_X_validation = np.zeros_like(Matrix_book, dtype=bool)\n",
        "\n",
        "# Set True for positions in the training mask where non-zero entries are selected\n",
        "mask_X[non_missing_indices[0][indices_X],\n",
        "       non_missing_indices[1][indices_X]] = True\n",
        "\n",
        "# Set True for positions in the validation mask where non-zero entries are selected\n",
        "mask_X_validation[non_missing_indices[0][indices_X_validation],\n",
        "                  non_missing_indices[1][indices_X_validation]] = True\n",
        "\n",
        "# Create the training matrix by retaining only the entries indicated by the training mask\n",
        "Matrix_book_X = np.where(mask_X, Matrix_book, 0)\n",
        "\n",
        "# Create the validation matrix by retaining only the entries indicated by the validation mask\n",
        "Matrix_book_X_validation = np.where(mask_X_validation, Matrix_book, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcF1aYRRaf5-",
        "outputId": "5d9b8b91-7c92-49d2-c055-280f6c0c9e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X matrix: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6168136\n",
            "Percentage of zeros: 98.722\n",
            "Number of non-zeros: 79864\n",
            "Percentage of non-zeros: 1.278\n"
          ]
        }
      ],
      "source": [
        "# Print details of X and validation matrices\n",
        "print(f\"Shape of X matrix: {Matrix_book_X.shape}\")\n",
        "print(f\"Maximum value: {np.max(Matrix_book_X)}\")\n",
        "print(f\"Minimum value: {np.min(Matrix_book_X)}\")\n",
        "print('-' * 60)\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book_X == 0)}\")\n",
        "print(\n",
        "    f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book_X == 0) / Matrix_book_X.size * 100, 3)}\")\n",
        "print(f\"Number of non-zeros: {np.count_nonzero(Matrix_book_X != 0)}\")\n",
        "print(\n",
        "    f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book_X != 0) / Matrix_book_X.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1uMt0C8eW8w",
        "outputId": "04c0ccfc-9c8e-4f1d-ec81-f5da948bcc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X validation matrix: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6228033\n",
            "Percentage of zeros: 99.68\n",
            "Number of non-zeros: 19967\n",
            "Percentage of non-zeros: 0.32\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of the X validation matrix\n",
        "print(f\"Shape of X validation matrix: {Matrix_book_X_validation.shape}\")\n",
        "\n",
        "# Print the maximum value in the X validation matrix\n",
        "print(f\"Maximum value: {np.max(Matrix_book_X_validation)}\")\n",
        "\n",
        "# Print the minimum value in the X validation matrix\n",
        "print(f\"Minimum value: {np.min(Matrix_book_X_validation)}\")\n",
        "\n",
        "# Print a separator line for readability\n",
        "print('-' * 60)\n",
        "\n",
        "# Count and print the number of zeros in the X validation matrix\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book_X_validation == 0)}\")\n",
        "\n",
        "# Calculate and print the percentage of zeros in the X validation matrix\n",
        "print(\n",
        "    f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book_X_validation == 0) / Matrix_book_X_validation.size * 100, 3)}\")\n",
        "\n",
        "# Count and print the number of non-zero entries in the X validation matrix\n",
        "print(\n",
        "    f\"Number of non-zeros: {np.count_nonzero(Matrix_book_X_validation != 0)}\")\n",
        "\n",
        "# Calculate and print the percentage of non-zero entries in the X validation matrix\n",
        "print(\n",
        "    f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book_X_validation != 0) / Matrix_book_X_validation.size * 100, 3)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdbFbN0redaS",
        "outputId": "b9495e23-f5a2-4d12-aab9-7baf54e9174b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total non-missing - non-missing X - non-missing X validation: 0\n",
            "Total non-missing - non-missing X - non-missing X validation (check Masks): 0\n"
          ]
        }
      ],
      "source": [
        "# Validate that the splits are correct by checking if the total number of non-missing entries\n",
        "# in the original matrix matches the sum of non-missing entries in the training and validation matrices\n",
        "\n",
        "# Compute the difference between the total non-missing entries in the original matrix and\n",
        "# the sum of non-missing entries in the training and validation matrices\n",
        "review_diff = np.count_nonzero(Matrix_book != 0) - np.count_nonzero(\n",
        "    Matrix_book_X != 0) - np.count_nonzero(Matrix_book_X_validation != 0)\n",
        "\n",
        "# Compute the difference using masks to ensure that the splits were done correctly\n",
        "review_diff2 = np.count_nonzero(\n",
        "    Matrix_book != 0) - np.sum(mask_X) - np.sum(mask_X_validation)\n",
        "\n",
        "# Print the difference to check if the non-missing entries were correctly distributed between\n",
        "# the training and validation matrices\n",
        "print(\n",
        "    f'Total non-missing - non-missing X - non-missing X validation: {review_diff}')\n",
        "\n",
        "# Print the difference using mask sums to double-check the correctness of the splits\n",
        "print(\n",
        "    f'Total non-missing - non-missing X - non-missing X validation (check Masks): {review_diff2}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vayjtd6GfCLg",
        "outputId": "05591cdd-e974-43d9-d365-3e2bad75195e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total missing: 6168136\n",
            "Total missing - non-missing X validation - missing data: 0\n"
          ]
        }
      ],
      "source": [
        "# Compute the total number of missing entries in the training matrix (Matrix_book_X)\n",
        "m = mask_X.sum()\n",
        "\n",
        "# Create a mask for missing entries by inverting the mask_X (i.e., non-zeros become True)\n",
        "mask_missing = ~mask_X\n",
        "\n",
        "# Compute the total number of missing entries in the original matrix\n",
        "total_missing_num = np.sum(mask_missing)\n",
        "\n",
        "# Compute the difference between the total number of missing entries and the sum of non-missing\n",
        "# entries in the validation matrix and the number of zeros in the original matrix\n",
        "review_diff3 = total_missing_num - \\\n",
        "    np.sum(mask_X_validation) - np.count_nonzero(Matrix_book == 0)\n",
        "\n",
        "# Print the total number of missing entries in the original matrix\n",
        "print(f'Total missing: {total_missing_num}')\n",
        "\n",
        "# Print the difference between the total number of missing entries, non-missing entries in the\n",
        "# validation matrix, and the number of zeros in the original matrix to check if all missing data\n",
        "# has been accounted for correctly\n",
        "print(f'Total missing - non-missing X validation - missing data: {review_diff3}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8LN0-HGf1Qg",
        "outputId": "1d144a3b-1839-4e2c-b23b-1cb2c581e82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Y: (6248, 1000)\n"
          ]
        }
      ],
      "source": [
        "# Initialize variables for matrix completion\n",
        "# Y = np.zeros(Matrix_book.shape)\n",
        "# tau =  5 * np.min(Matrix_book.shape)  # Page 20\n",
        "# Initialize variables for matrix completion\n",
        "Y = 5 * np.random.rand(*Matrix_book.shape)  # Random matrix between 0 and 5\n",
        "delta = 1.25 * Matrix_book.size / (~mask_X).sum()  # Calculate delta Page 17\n",
        "tau = 4600  # Set tau value\n",
        "\n",
        "print(f\"Shape of Y: {Y.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFb0zGimgT3H",
        "outputId": "83a8f14f-4c68-4184-8816-21ad02ff8fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1  -  Relative Error: 0.7051\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 10  -  Relative Error: 0.3935\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 20  -  Relative Error: 0.2351\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 30  -  Relative Error: 0.1714\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 40  -  Relative Error: 0.1382\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 50  -  Relative Error: 0.1185\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 60  -  Relative Error: 0.1057\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 70  -  Relative Error: 0.0970\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 80  -  Relative Error: 0.0907\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 90  -  Relative Error: 0.0843\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 100  -  Relative Error: 0.0799\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 110  -  Relative Error: 0.0765\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 120  -  Relative Error: 0.0736\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 130  -  Relative Error: 0.0710\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 140  -  Relative Error: 0.0691\n",
            "------------------------------------------------------------\n",
            "\n",
            "Iteration 150  -  Relative Error: 0.0675\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize a dictionary to store the relative errors for each iteration\n",
        "RE_list = {}\n",
        "\n",
        "# Perform the SVT algorithm for 150 iterations\n",
        "for i in range(150):\n",
        "    # Compute the Singular Value Decomposition (SVD) of the current matrix Y\n",
        "    u, s, vh = svd(Y, full_matrices=False)\n",
        "\n",
        "    # Apply soft-thresholding to the singular values\n",
        "    s_t = np.maximum(s - tau, 0)\n",
        "\n",
        "    # Reconstruct the matrix Z using the thresholded singular values\n",
        "    Z = (u[:, :1000] * s_t) @ vh\n",
        "\n",
        "    # Compute the prediction error matrix P\n",
        "    P = Matrix_book_X - Z\n",
        "\n",
        "    # Set the entries corresponding to missing data in the prediction error matrix to 0\n",
        "    P[mask_missing] = 0\n",
        "\n",
        "    # Update the matrix Y using the step size delta and the prediction error matrix P\n",
        "    Y0 = Y.copy()\n",
        "    Y = Y0 + delta * P\n",
        "\n",
        "    # Compute the relative error of the reconstructed matrix Z with respect to the validation matrix\n",
        "    relative_error = np.sum((Z[mask_X_validation] - Matrix_book_X_validation[mask_X_validation])\n",
        "                            ** 2) / np.sum(Matrix_book_X_validation[mask_X_validation]**2)\n",
        "\n",
        "    # Optionally compute the Mean Squared Error (MSE) for additional evaluation\n",
        "    MSE = np.mean(\n",
        "        (Z[mask_X_validation] - Matrix_book_X_validation[mask_X_validation])**2)\n",
        "\n",
        "    # Store the relative error for the current iteration in the dictionary\n",
        "    RE_list[i] = relative_error\n",
        "\n",
        "    # Print the relative error for the current iteration\n",
        "    if (i + 1) % 10 == 0 or i == 0:\n",
        "        print(f\"Iteration {i+1}  -  Relative Error: {relative_error:.4f}\")\n",
        "        print('-' * 60 + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SYRFFsFJgf6m"
      },
      "outputs": [],
      "source": [
        "# # Print relative errors for all iterations\n",
        "# for key, value in RE_list.items():\n",
        "#     print(f\"Iteration {key+1}, RE: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "WTfIqQBsiCbX",
        "outputId": "c162365a-5b77-4fc6-b36f-2773f858233d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract the iteration numbers and corresponding errors from the dictionary\n",
        "iterations = [i + 1 for i in RE_list.keys()]\n",
        "errors = list(RE_list.values())\n",
        "\n",
        "# Create a new figure for plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the relative error over iterations with a line plot\n",
        "plt.plot(iterations, errors, linestyle='-', color='g')  # Plot with line only\n",
        "\n",
        "# Set the x-axis ticks for better readability\n",
        "plt.xticks(ticks=range(min(iterations) - 1, max(iterations) - 1 + 30, 10))\n",
        "\n",
        "# Label the x-axis and y-axis\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Relative Error')\n",
        "\n",
        "# Set the title for the plot\n",
        "plt.title('Relative Error over Iterations')\n",
        "\n",
        "# Annotate the plot with the relative error percentage at the final iteration\n",
        "plt.annotate(f'{RE_list[149] * 100:.2f}%',\n",
        "             (140, RE_list[149] + 0.05),\n",
        "             textcoords=\"offset points\",\n",
        "             xytext=(0, 5),\n",
        "             ha='center',\n",
        "             fontsize=9,\n",
        "             color='red')\n",
        "\n",
        "# Draw an arrow indicating the final relative error point on the plot\n",
        "plt.annotate('',\n",
        "             xy=(149, RE_list[149] + 0.01),\n",
        "             xytext=(140, RE_list[149] + 0.05),\n",
        "             arrowprops=dict(facecolor='red', edgecolor='red', arrowstyle='->', linewidth=1.0))\n",
        "\n",
        "# Set the limits for the x-axis and y-axis\n",
        "plt.xlim(0, 150)\n",
        "plt.ylim(0, 0.8)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-KDMiN2H8GY"
      },
      "source": [
        "## **Conclusion**\n",
        "\n",
        "The implementation of the Singular Value Thresholding (SVT) algorithm successfully demonstrated its ability to recover low-rank matrices from sparse data. Based on the methodology detailed in the paper [**A Singular Value Thresholding Algorithm for Matrix Completion**](https://arxiv.org/abs/0810.3286), the following key outcomes were achieved:\n",
        "\n",
        "### Summary of Findings\n",
        "\n",
        "1. **Matrix Completion Efficiency**: The SVT algorithm effectively completed matrix recovery on the GoodBooks dataset, which had a sparse matrix with approximately **98.4%** missing values. By utilizing 80% of the non-zero elements for training and 20% for validation, the algorithm efficiently reconstructed the missing values.\n",
        "\n",
        "2. **Algorithm Performance**:\n",
        "   - **Relative Error**: The SVT algorithm achieved a relative error of **6.75%** after **150 iterations**, indicating high accuracy in approximating the original matrix with a low-rank representation.\n",
        "   - **Convergence**: The convergence behavior was demonstrated through plots showing the decrease in relative error over iterations. The algorithm exhibited steady convergence with decreasing error as iterations progressed.\n",
        "\n",
        "3. **Parameter Tuning**:\n",
        "   - **Threshold $\\tau$**: The selected threshold of $\\tau = 4600$ and step size $\\delta = 1.26$ were instrumental in achieving optimal results. These parameters influenced the soft-thresholding and update rules, impacting both convergence speed and accuracy.\n",
        "\n",
        "4. **Practical Implications**: The results underscore the SVT algorithm's potential for practical applications such as recommendation systems and collaborative filtering. Its capability to handle large, sparse matrices efficiently makes it a valuable tool in data science and machine learning.\n",
        "\n",
        "### Visual Insights\n",
        "\n",
        "- **Convergence Plots**: The provided plots illustrate the SVT algorithm's convergence, showcasing the decline in relative error over the course of the iterations.\n",
        "- **Performance Metrics**: Tables and graphs detail the accuracy of the recovered matrix and the relative errors for each iteration, validating the algorithm's effectiveness.\n",
        "\n",
        "In conclusion, the SVT algorithm proves to be a robust and efficient method for matrix completion, effectively recovering low-rank matrices from sparse data with notable accuracy. However, **one notable weakness of the SVT algorithm is its computational expense**, particularly for large-scale problems where singular value thresholding operations become increasingly costly. Despite this, the results confirm the theoretical advantages of the SVT approach and highlight its practical applicability in real-world scenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"#9B1B30\">Appendix - Collaborative Filtering</font>\n",
        "Collaborative filtering is a technique used to identify relevant items for a specific user by:  \n",
        "- Filtering through a large set of items to find the most relevant ones.  \n",
        "- Considering the preferences and behaviors of many users to make recommendations."
      ],
      "metadata": {
        "id": "lyOcI5YoKtUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User-Product Matrix:\\n\", Matrix_book_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wcacigsNoFT",
        "outputId": "ac458e88-a67a-4c31-d5e7-38b852a5043b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-Product Matrix:\n",
            " [[5 0 3 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]\n",
            " [5 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 4]\n",
            " [0 0 0 ... 0 0 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print details of X and validation matrices\n",
        "print(f\"Shape of X matrix: {Matrix_book_X.shape}\")\n",
        "print(f\"Maximum value: {np.max(Matrix_book_X)}\")\n",
        "print(f\"Minimum value: {np.min(Matrix_book_X)}\")\n",
        "print('-' * 60)\n",
        "print(f\"Number of zeros: {np.count_nonzero(Matrix_book_X == 0)}\")\n",
        "print(f\"Percentage of zeros: {round(np.count_nonzero(Matrix_book_X == 0) / Matrix_book_X.size * 100, 3)}\")\n",
        "print(f\"Number of non-zeros: {np.count_nonzero(Matrix_book_X != 0)}\")\n",
        "print( f\"Percentage of non-zeros: {round(np.count_nonzero(Matrix_book_X != 0) / Matrix_book_X.size * 100, 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRvNg1i5Nlop",
        "outputId": "47096f8c-2351-45fd-e1fd-2eaedfc9b1dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X matrix: (6248, 1000)\n",
            "Maximum value: 5\n",
            "Minimum value: 0\n",
            "------------------------------------------------------------\n",
            "Number of zeros: 6168136\n",
            "Percentage of zeros: 98.722\n",
            "Number of non-zeros: 79864\n",
            "Percentage of non-zeros: 1.278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#9B1B30\"> A1 - User-Based Collaborative Filtering </font>\n",
        "\n",
        "\n",
        "### Overview  \n",
        "User-based collaborative filtering recommends items to a user by identifying other users with similar preferences. It operates in the following way:  \n",
        "\n",
        "1. **Find users who are most similar to the target user (neighbors)**  \n",
        "   - This is done by comparing the preferences of the target user to those of other users.  \n",
        "\n",
        "2. **Recommend items that the user has not yet purchased**  \n",
        "   - The recommendation is based on items most preferred by the userâ€™s neighbors.  \n",
        "\n",
        "### Steps  \n",
        "\n",
        "#### **1. Normalize by Subtracting the User Mean**  \n",
        "For a given user $u$, normalize the ratings by subtracting the mean rating of that user:  \n",
        "\n",
        "$$\n",
        "\\tilde{r}_{ui} = r_{ui} - \\bar{r}_u\n",
        "$$\n",
        "\n",
        "where $ \\bar{r}_u $ is the mean of all non-missing ratings of user $ u $.  \n",
        "\n",
        "#### **2. Calculate the Similarity Between Two Users (User $ u $ and User $ v $)**  \n",
        "The similarity between users $ u $ and $ v $ is computed using Cosine Similarity:  \n",
        "\n",
        "$$\n",
        "s_{uv} = \\frac{\\sum_{i \\in I_u \\cap I_v} \\tilde{r}_{ui} \\cdot \\tilde{r}_{vi}}{\\sqrt{\\sum_{i \\in I_u \\cap I_v} \\tilde{r}_{ui}^2} \\cdot \\sqrt{\\sum_{i \\in I_u \\cap I_v} \\tilde{r}_{vi}^2}}\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ I_u \\cap I_v $ is the set of all items rated by both users $ u $ and $ v $.  \n",
        "- $ s_{uv} $ measures the similarity between users based on their common ratings.  \n",
        "\n",
        "#### **3. Predict a Missing Rating Using a Weighted Average**  \n",
        "To predict a missing rating for a user, compute:  \n",
        "\n",
        "$$\n",
        "r_{ui} = \\frac{\\sum_{v, i \\in I_v} s_{uv} \\cdot \\tilde{r}_{vi}}{\\sum_{v, i \\in I_v} s_{uv}} + \\bar{r}_u\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ I_v $ represents the set of users who have rated item $ i $.  \n",
        "- The predicted rating is a weighted sum of the ratings given by similar users, adjusted by the target userâ€™s mean rating.  \n"
      ],
      "metadata": {
        "id": "nar72knQLITp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Demo code for the target user (index = 0)**"
      ],
      "metadata": {
        "id": "JMsTl4iPWmwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target the first user (index 0)\n",
        "target_index = 0\n",
        "print(Matrix_book_X[target_index, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNJDZdU0QYq3",
        "outputId": "041d5fad-dc9d-4e23-9c0a-5b3ab559c397"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 0 3 0 0 5 0 0 0 0 0 4 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 3 4 5 0 0 0 4 4 0\n",
            " 0 3 0 4 0 0 0 0 4 5 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 4 0 0 4 4 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 4 5 4 3 4 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 3 4 3 0 0 0 4 5 0 0 0 0 0 0 0\n",
            " 0 0 4 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 3 0 0\n",
            " 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 5 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 5 3 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 2 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 0 0 0 4 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 1:\n",
        "#Calculate user mean\n",
        "user_means = np.array([np.sum(row) / np.count_nonzero(row) if np.count_nonzero(row) > 0 else 0 for row in Matrix_book_X])\n",
        "\n",
        "# Normalize by subtracting user mean\n",
        "norm_ratings = (Matrix_book_X - user_means[:, None]) * (Matrix_book_X != 0)\n",
        "\n",
        "# Print basic information about norm_ratings\n",
        "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
        "    print(\"Normalized Ratings:\\n\")\n",
        "    display(pd.DataFrame(norm_ratings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "uE1_dnluKsyY",
        "outputId": "78bccf42-e276-4563-9c23-138967465e2f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Ratings:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
              "0     1.39 -0.00 -0.61 -0.00 -0.00  1.39 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "1    -0.41 -0.00 -0.00  1.59 -0.00 -0.00 -0.41 -0.00 -0.00 -0.00  ... -0.00   \n",
              "2     1.36 -0.00 -2.64 -0.00 -0.00 -0.00 -0.00 -0.64 -0.00 -0.00  ... -0.00   \n",
              "3     0.15 -0.85 -0.00  1.15  1.15 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "4     0.52 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "6243  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
              "6244 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6245  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
              "6246 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6247 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "\n",
              "       991   992   993   994   995   996   997   998   999  \n",
              "0    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "1    -0.41 -0.00 -0.41 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "2    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "3    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.15 -0.00  \n",
              "4    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "6243  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "6244 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.00  \n",
              "6245  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  \n",
              "6246 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.00  \n",
              "6247 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.00  \n",
              "\n",
              "[6248 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4dca78c-c0cd-436e-ab99-be76c4c67415\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.39</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.39</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.36</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-2.64</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>1.15</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.15</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.52</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6243</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6244</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6245</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6246</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6247</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6248 rows Ã— 1000 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4dca78c-c0cd-436e-ab99-be76c4c67415')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4dca78c-c0cd-436e-ab99-be76c4c67415 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4dca78c-c0cd-436e-ab99-be76c4c67415');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3cefde5-edda-4ce5-a7dc-8ead29f0bdb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3cefde5-edda-4ce5-a7dc-8ead29f0bdb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3cefde5-edda-4ce5-a7dc-8ead29f0bdb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2:\n",
        "# Get normalized ratings for the target user\n",
        "target_norm = norm_ratings[target_index, :]\n",
        "\n",
        "# Compare the Target row with all other rows\n",
        "common_mask = (Matrix_book_X != 0) & (Matrix_book_X[target_index, :] != 0)\n",
        "\n",
        "# Only consider co-rated users (those who share at least one non-zero rating)\n",
        "dot_products = np.sum(norm_ratings * (common_mask * target_norm[None, :]), axis=1)\n",
        "\n",
        "# Compute norms using only the common ratings:\n",
        "target_norms = np.sqrt(np.sum((target_norm[None, :] * common_mask)**2, axis=1))\n",
        "user_norms = np.sqrt(np.sum((norm_ratings * common_mask)**2, axis=1))\n",
        "\n",
        "# Compute cosine similarity: dot / (norm_target * norm_user), handling division by zero.\n",
        "denom = target_norms * user_norms\n",
        "sims = np.divide(dot_products, denom, out=np.zeros_like(dot_products), where=denom != 0)\n",
        "sims[target_index] = 0\n",
        "\n",
        "# Print the cosine similarities\n",
        "print(\"\\nCosine similarities with target item:\\n\", pd.DataFrame(sims, columns=[\"Cosine Similarity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaXIbwwuOldU",
        "outputId": "33971775-e4cd-4b3e-9028-2c68d9948d7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarities with target item:\n",
            "       Cosine Similarity\n",
            "0              0.000000\n",
            "1              0.457633\n",
            "2              0.712432\n",
            "3             -0.018325\n",
            "4              0.431597\n",
            "...                 ...\n",
            "6243           0.000000\n",
            "6244           0.000000\n",
            "6245           0.000000\n",
            "6246           0.000000\n",
            "6247           0.000000\n",
            "\n",
            "[6248 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Predict missing ratings for the target user\n",
        "# Start with the target user's existing ratings\n",
        "predictions = Matrix_book_X[target_index, :].copy()\n",
        "\n",
        "# Loop over all items (columns) to predict missing ratings (where the rating is 0)\n",
        "for j in range(Matrix_book_X.shape[1]):\n",
        "    if Matrix_book_X[target_index, j] == 0:  # Only predict for missing ratings (zero values)\n",
        "        rated_mask = Matrix_book_X[:, j] != 0  # Mask for users who have rated item j\n",
        "        numerator = np.sum(sims[rated_mask] * norm_ratings[rated_mask, j])  # Compute weighted sum of ratings\n",
        "        denominator = np.sum(np.abs(sims[rated_mask]))  # Sum of absolute similarities (normalization factor)\n",
        "\n",
        "        if denominator > 0:  # If there are any co-rated users\n",
        "            predictions[j] = user_means[target_index] + (numerator / denominator)  # Predict rating using weighted average\n",
        "        else:  # If no co-rated users, use the user's mean rating\n",
        "            predictions[j] = user_means[target_index]\n",
        "\n",
        "# Print original ratings and predicted ratings for the target user\n",
        "print(\"\\nOriginal ratings (target user):\")\n",
        "print(Matrix_book_X[target_index])\n",
        "print(\"\\nPredicted ratings (target user):\")\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPQjxV1yOu9p",
        "outputId": "11f9b8d6-7752-4c10-cf05-d7e32dd3d083"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original ratings (target user):\n",
            "[5 0 3 0 0 5 0 0 0 0 0 4 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 3 4 5 0 0 0 4 4 0\n",
            " 0 3 0 4 0 0 0 0 4 5 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 4 0 0 4 4 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 4 5 4 3 4 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 3 4 3 0 0 0 4 5 0 0 0 0 0 0 0\n",
            " 0 0 4 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 3 0 0\n",
            " 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 5 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 5 3 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 2 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 0 0 0 4 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n",
            "\n",
            "Predicted ratings (target user):\n",
            "[5 3 3 3 3 5 3 3 3 3 3 4 3 3 3 3 3 3 3 4 3 3 3 3 4 3 4 3 3 4 5 3 3 3 4 4 3\n",
            " 3 3 3 4 3 3 3 3 4 5 3 2 3 2 2 3 3 3 1 3 3 3 3 3 3 3 3 3 4 3 3 4 4 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 5 4 3 4 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 4 5 3 3 3 3 3 3 3\n",
            " 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 5 4 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 4 3 3 3 4 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 2 3 3 3 3 3 4 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2\n",
            " 3 3 3 3 3 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 4 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3\n",
            " 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 3 3 3 3 3 3 3 3 3\n",
            " 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"#9B1B30 \">A2 - Item-Based Collaborative Filtering </font>\n",
        "\n",
        "\n",
        "### Overview  \n",
        "Item-based collaborative filtering recommends items to a user by identifying items similar to those the user has already rated. It operates in the following way:  \n",
        "\n",
        "1. **Find items that are most similar to the items the user has rated**  \n",
        "   - This is done by comparing the ratings of items that the user has rated to those of other items.  \n",
        "\n",
        "2. **Recommend items that the user has not yet rated**  \n",
        "   - The recommendation is based on items most similar to those that the user has rated highly.  \n",
        "\n",
        "### Steps  \n",
        "\n",
        "#### **1. Normalize by Subtracting the Item Mean**  \n",
        "For a given item $i$, normalize the ratings by subtracting the mean rating of that item:  \n",
        "\n",
        "$$\n",
        "\\tilde{r}_{ui} = r_{ui} - \\bar{r}_i\n",
        "$$\n",
        "\n",
        "where $ \\bar{r}_i $ is the mean of all non-missing ratings for item $ i $.  \n",
        "\n",
        "#### **2. Calculate the Similarity Between Two Items (Item $i$ and Item $j$)**  \n",
        "The similarity between items $i$ and $j$ is computed using Cosine Similarity:  \n",
        "\n",
        "$$\n",
        "s_{ij} = \\frac{\\sum_{u \\in U_i \\cap U_j} \\tilde{r}_{ui} \\cdot \\tilde{r}_{uj}}{\\sqrt{\\sum_{u \\in U_i \\cap U_j} \\tilde{r}_{ui}^2} \\cdot \\sqrt{\\sum_{u \\in U_i \\cap U_j} \\tilde{r}_{uj}^2}}\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ U_i \\cap U_j $ is the set of all users who have rated both item $i$ and item $j$.  \n",
        "- $ s_{ij} $ measures the similarity between items based on their common ratings by users.  \n",
        "\n",
        "#### **3. Predict a Missing Rating Using a Weighted Average**  \n",
        "To predict a missing rating for a user on item $i$, compute:  \n",
        "\n",
        "$$\n",
        "r_{ui} = \\frac{\\sum_{j \\in I_u} s_{ij} \\cdot \\tilde{r}_{uj}}{\\sum_{j \\in I_u} s_{ij}} + \\bar{r}_i\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ I_u $ represents the set of items that the user $ u $ has rated.  \n",
        "- The predicted rating is a weighted sum of the ratings for similar items, adjusted by the mean rating of item $i$.  \n"
      ],
      "metadata": {
        "id": "OrcPQKq3Mx3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Demo code for the target user (index = 0)**"
      ],
      "metadata": {
        "id": "4TjoZcXdZAyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Compute the mean rating for each item (column)\n",
        "item_means = np.nanmean(np.where(Matrix_book_X != 0, Matrix_book_X, np.nan), axis=0)  # Ignore missing ratings (0)\n",
        "#item_means = np.array([np.sum(Matrix_book_X[:, col]) / np.count_nonzero(Matrix_book_X[:, col]) \\\n",
        "# if np.count_nonzero(Matrix_book_X[:, col]) > 0 else 0 for col in range(Matrix_book_X.shape[1])])\n",
        "\n",
        "\n",
        "# Normalize the ratings by subtracting the item mean (for each item)\n",
        "norm_ratings = (Matrix_book_X - item_means) * (Matrix_book_X != 0)  # Only normalize non-zero ratings\n",
        "\n",
        "# Print normalized ratings to check\n",
        "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
        "    print(\"Normalized Ratings:\\n\")\n",
        "    display(pd.DataFrame(norm_ratings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "xR7v9w2FNFtE",
        "outputId": "918bf233-727d-4778-da70-c9cca0c24939"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Ratings:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
              "0     0.77 -0.00 -0.03 -0.00 -0.00  0.89 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "1    -1.23 -0.00 -0.00  0.57 -0.00 -0.00 -0.82 -0.00 -0.00 -0.00  ... -0.00   \n",
              "2     0.77 -0.00 -2.03 -0.00 -0.00 -0.00 -0.00 -0.85 -0.00 -0.00  ... -0.00   \n",
              "3    -0.23 -1.38 -0.00  0.57  1.02 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "4    -0.23 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "6243 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6244 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6245 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6246 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "6247 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  ... -0.00   \n",
              "\n",
              "       991   992   993   994   995   996   997   998   999  \n",
              "0    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "1    -0.53 -0.00 -1.18 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "2    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "3    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.07 -0.00  \n",
              "4    -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "6243 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "6244 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.04  \n",
              "6245 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  \n",
              "6246 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00  0.04  \n",
              "6247 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.96  \n",
              "\n",
              "[6248 rows x 1000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b543c008-e5dc-4a7c-a00c-9f3876515bbd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>992</th>\n",
              "      <th>993</th>\n",
              "      <th>994</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.77</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.89</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.23</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.82</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-1.18</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.77</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-2.03</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.23</td>\n",
              "      <td>-1.38</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.02</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.23</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6243</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6244</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6245</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6246</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6247</th>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6248 rows Ã— 1000 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b543c008-e5dc-4a7c-a00c-9f3876515bbd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b543c008-e5dc-4a7c-a00c-9f3876515bbd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b543c008-e5dc-4a7c-a00c-9f3876515bbd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2f18484-2e6b-44f2-bac6-269e15f7c3ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2f18484-2e6b-44f2-bac6-269e15f7c3ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2f18484-2e6b-44f2-bac6-269e15f7c3ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Compute cosine similarities between the target item and all other items\n",
        "# Select a target item (for example, the first item, index 0)\n",
        "target_index = 0\n",
        "target_norm = norm_ratings[:, target_index]  # Ratings for the target item\n",
        "\n",
        "# Compute dot products for cosine similarity\n",
        "dot_products = np.sum(norm_ratings * (common_mask * target_norm[:, None]), axis=0)\n",
        "\n",
        "# Compute norms of the items (only considering common ratings)\n",
        "target_norms = np.sqrt(np.sum((target_norm[:, None] * common_mask)**2, axis=0))\n",
        "item_norms = np.sqrt(np.sum((norm_ratings * common_mask)**2, axis=0))\n",
        "\n",
        "# Compute cosine similarity between items (dot product / norms)\n",
        "denom = target_norms * item_norms\n",
        "sims = np.divide(dot_products, denom, out=np.zeros_like(dot_products), where=denom != 0)  # Cosine similarity\n",
        "sims[target_index] = 0  # Exclude self-similarity\n",
        "\n",
        "# Print the cosine similarities\n",
        "print(\"\\nCosine similarities with target item:\\n\", pd.DataFrame(sims, columns=[\"Cosine Similarity\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMEEGn9HTgHJ",
        "outputId": "123172ea-c5d6-47e0-ce78-1389628a3577"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarities with target item:\n",
            "      Cosine Similarity\n",
            "0             0.000000\n",
            "1             0.000000\n",
            "2             0.049077\n",
            "3             0.000000\n",
            "4             0.000000\n",
            "..                 ...\n",
            "995           0.000000\n",
            "996           0.000000\n",
            "997           0.000000\n",
            "998           0.000000\n",
            "999           0.000000\n",
            "\n",
            "[1000 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Predict missing ratings for the target user\n",
        "# Start with the target user's existing ratings\n",
        "predictions = Matrix_book_X[target_index, :].copy()  # Copy target user's ratings\n",
        "\n",
        "# Loop over all items (columns) to predict missing ratings (where the rating is 0)\n",
        "for j in range(Matrix_book_X.shape[1]):\n",
        "    if Matrix_book_X[target_index, j] == 0:  # Only predict for missing ratings (zero values)\n",
        "        rated_mask = Matrix_book_X[target_index, :] != 0  # Mask for items rated by the target user\n",
        "        numerator = np.sum(sims[rated_mask] * norm_ratings[target_index, rated_mask])  # Weighted sum of ratings\n",
        "        denominator = np.sum(np.abs(sims[rated_mask]))  # Sum of absolute similarities (normalization factor)\n",
        "\n",
        "        if denominator > 0:  # If there are any similar items rated by the user\n",
        "            predictions[j] = item_means[j] + (numerator / denominator)  # Predict rating using weighted average\n",
        "        else:  # If no similar items, use the item's mean rating\n",
        "            predictions[j] = item_means[j]\n",
        "\n",
        "# Print original ratings and predicted ratings for the target user\n",
        "print(\"\\nOriginal ratings (target user):\")\n",
        "print(Matrix_book_X[target_index])\n",
        "print(\"\\nPredicted ratings (target user):\")\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqU0O_DKTi8a",
        "outputId": "0b89900a-fee8-4cc9-9739-c0cec0924442"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original ratings (target user):\n",
            "[5 0 3 0 0 5 0 0 0 0 0 4 0 0 0 0 0 0 0 4 0 3 0 0 0 0 0 0 3 4 5 0 0 0 4 4 0\n",
            " 0 3 0 4 0 0 0 0 4 5 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 4 0 0 4 4 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 4 5 4 3 4 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 3 4 3 0 0 0 4 5 0 0 0 0 0 0 0\n",
            " 0 0 4 0 3 0 0 0 0 0 0 0 0 0 3 0 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 3 0 0\n",
            " 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 5 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 5 3 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 2 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2\n",
            " 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 4 0 0 0 0 4 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0\n",
            " 0]\n",
            "\n",
            "Predicted ratings (target user):\n",
            "[5 4 3 4 4 5 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 3 4 4 3 4 5 4 4 3 4 4 4\n",
            " 4 3 3 4 4 4 3 4 4 5 4 3 4 2 3 3 4 4 1 4 4 4 4 3 4 4 4 4 4 4 4 4 4 3 4 3 4\n",
            " 3 4 4 3 4 4 4 4 3 4 4 4 4 4 4 4 3 4 4 4 4 3 4 3 3 4 3 4 5 4 3 4 3 3 4 4 3\n",
            " 4 4 4 4 4 4 4 4 3 4 3 3 4 4 4 4 4 4 3 4 3 4 3 4 3 4 3 3 4 5 4 4 4 3 4 4 3\n",
            " 4 4 4 3 3 4 4 3 4 4 4 3 4 4 3 4 4 3 4 4 3 3 4 4 3 3 4 4 4 4 4 4 4 3 3 4 4\n",
            " 3 3 4 4 5 4 4 4 3 4 4 3 4 4 4 2 3 3 4 4 3 4 4 4 3 4 3 3 3 5 4 4 3 4 4 4 4\n",
            " 4 3 4 4 4 3 4 4 4 4 4 4 4 3 4 3 4 3 4 4 4 3 4 3 3 4 4 4 4 4 4 3 3 3 4 4 4\n",
            " 3 3 4 4 3 4 3 4 3 3 4 4 4 3 4 3 4 4 4 5 3 3 4 4 3 4 3 3 4 4 4 4 4 4 4 4 4\n",
            " 4 3 3 4 3 4 3 4 3 3 4 3 3 3 4 4 4 4 3 4 4 4 3 4 4 4 3 4 4 3 4 4 4 4 3 4 4\n",
            " 4 4 4 4 3 4 3 4 2 3 4 3 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2\n",
            " 4 4 4 4 3 4 4 4 3 4 3 3 3 4 4 4 3 4 4 3 4 3 4 4 4 4 3 4 3 4 3 4 3 4 4 4 4\n",
            " 4 4 3 3 4 4 3 3 4 4 4 4 3 4 4 3 4 3 4 4 3 4 4 4 4 4 3 3 4 4 4 4 4 4 4 4 4\n",
            " 4 4 3 3 3 3 3 4 4 4 3 4 4 4 4 4 4 4 4 4 3 4 4 4 3 4 4 4 4 4 4 4 4 3 3 4 4\n",
            " 4 4 3 4 3 4 4 4 4 3 3 4 4 3 4 4 4 3 3 3 4 4 4 3 3 4 4 3 4 4 4 4 4 4 4 3 4\n",
            " 3 4 4 4 4 4 3 3 3 4 3 4 3 4 3 4 4 4 4 3 4 4 4 4 4 4 4 3 4 3 4 4 4 3 4 4 4\n",
            " 3 3 3 4 3 4 4 3 4 4 3 4 4 3 4 3 4 3 4 3 3 4 3 4 4 4 3 3 3 4 3 3 4 4 3 4 4\n",
            " 4 4 3 3 4 4 4 3 4 4 4 3 3 3 4 4 3 4 3 4 4 3 4 4 3 4 4 4 4 3 4 3 3 4 4 4 3\n",
            " 4 3 4 3 3 3 4 4 3 4 3 4 4 3 4 3 3 3 3 3 3 4 3 4 4 3 3 3 3 3 3 4 4 4 4 4 3\n",
            " 4 4 4 4 4 4 4 3 4 3 4 4 4 4 4 3 3 3 3 3 4 4 3 4 4 3 3 3 4 3 4 4 4 4 3 3 3\n",
            " 4 3 3 3 3 4 3 4 4 4 4 3 3 4 3 3 4 4 4 4 3 4 4 3 4 4 3 4 3 4 4 4 4 4 4 4 4\n",
            " 3 4 4 4 4 4 4 3 4 4 4 4 4 4 4 3 4 4 4 4 3 4 4 3 4 4 4 4 4 3 4 3 4 4 4 4 3\n",
            " 3 4 4 3 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 3 4 3 4 4 4 4 4 3 3\n",
            " 4 3 4 3 4 4 3 4 3 3 3 4 4 4 4 4 3 3 3 3 4 4 4 3 3 4 4 4 3 4 4 4 3 4 3 3 3\n",
            " 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 3 4 3 4 4 4 3 4 4 4 4 3 4 3 4 4 3 4 3 4\n",
            " 4 4 4 4 4 4 3 4 4 3 4 4 4 4 3 3 4 3 4 3 3 4 3 4 4 4 3 3 4 4 3 4 4 3 4 3 3\n",
            " 3 3 4 4 4 3 4 4 3 4 4 4 4 4 4 4 4 4 3 3 3 4 4 4 4 4 3 4 4 3 4 3 4 3 4 4 4\n",
            " 3 4 3 4 3 3 3 4 4 3 3 4 3 3 4 4 4 4 3 4 4 4 4 3 4 4 4 4 4 3 4 4 4 4 4 4 4\n",
            " 4]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}