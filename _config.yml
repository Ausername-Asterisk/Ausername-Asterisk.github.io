# Site
repository: Ausername-Asterisk/Ausername-Asterisk.github.io
favicon: assets/images/favicon12.ico  

# Content configuration version
version: 2  

# Personal info : AI and Data Science Repository: Uniting Theory and Practice
name: Ken K. Hong
title: Ken K. HongÔΩúData Science & Analytics
title2: Data Science & Analytics | MS in Computational Data Analytics (Data Science) Candidate @ Georgia Tech üëã üë®‚ÄçüöÄ
description: This repository documents my academic journey at Georgia Tech by capturing what I've learned, the research I'm passionate about, and my goals in Artificial Intelligence and Data Science. It will continue evolving as I grow and develop in these fields. üëã 
email: 
website: 

# Dark Mode (true/false/never)
darkmode: false

# Social links
# twitter_username: kkhong42
github_username: Ausername-Asterisk
# stackoverflow_username: "00000001"
# dribbble_username: kkhong42
# facebook_username: kkhong42
# flickr_username: kkhong42
# instagram_username: kkhong42
linkedin_username: kkhong42
# xing_username: kkhong42
# pinterest_username: kkhong42
# youtube_username: kkhong42
# googleplus_username: +kkhong42
# orcid_username: 0000-0000-0000-0000

# Additional icon links
# additional_links:
# - title: itsgoingto.be
#  icon: fas fa-globe
#   url: https://www.itsgoingto.be
# - title: another link
#   icon: font awesome brand icon name (eg. fab fa-twitter) (https://fontawesome.com/icons?d=gallery&m=free)
#   url: Link url (eg. https://google.com)

# Google Analytics and Tag Manager
# Using more than one of these may cause issues with reporting
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"
# google_analytics: "UA-00000000-0"

# About Section
about_title: Data Touches Everything
about_profile_image: assets/images/profilekkh.jpg 
about_content: | # this will include new lines to allow paragraphs
    This repository serves as a comprehensive record of my academic journey and a platform for organizing my knowledge and goals in AI and Data Science as I pursue my Data Analytics and Data Science master's degree at Georgia Tech, guided by the [Artificial Intelligence Roadmap](https://i.am.ai/roadmap/#note). With a strong foundation in essential components that underlie modern data science methodologies, key areas include:

    - **Optimization:** Fundamental techniques crucial for developing machine learning algorithms, sample code implemented using Python.

    - **Machine Learning:** Focus on algorithms suited for handling large datasets with low-dimensional features, encompassing foundational tasks such as regression, classification, clustering, and dimensionality reduction. Advanced ensemble methods like boosting and bagging are also explored for enhanced model performance.

    - **High-Dimensional Statistics:** Specialized methods for extracting informative features from datasets characterized by high dimensionality and limited samples. This includes advanced techniques in image processing, tensor analysis, and regularization.

    - **Deep Learning:** Advanced modeling techniques designed for large-scale datasets and complex feature sets. This includes Gradient Descent Optimization (Adam), Multilayer Perceptrons (MLPs), Convolutional Neural Networks (CNNs), and advanced architectures such as Long Short-Term Memory (LSTM), Transformers, Generative Adversarial Networks (GANs), and Diffusion models.

    - **Reinforcement Learning:** Examines trial-and-error policy learning in stochastic environments via MDPs/POMDPs; dynamic programming (Bellman updates); temporal-difference methods (Q-learning, SARSA); function approximation; exploration strategies (Œµ-greedy, UCB); policy-gradient and actor-critic techniques; and multi-agent/game-theoretic frameworks. (Work in Progress üåü)
    
content:   

  - title:  # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Table of Contents
        caption: 
        sub_title: 
        quote: >
        description: | # this will include new lines to allow paragraphs
            - [Featured Projects](#featured-project)
            - [Work in Progress](#work_in_progress)
            - [Optimization](#optimization)
            - [Machine Learning](#machine-learning)
            - [High-Dimensional Statistics](#high-dimensional-statistics)
            - [Deep Learning](#deep-learning)
            - [Reinforcement Learning](#reinforcement-learning)
            - [Supplementary Information](#supplementary-information)
            - [Future Update](#future-update)


  - title:  # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Featured Projects
        caption: 
        sub_title: 
        quote: >
        description: | # this will include new lines to allow paragraphs
        

            - **Beyond Yelp Stars: Better Review Insights for Businesses & Customers ü§ù**  <a id="featured-project"></a>
              - NLP, Fine-Tuning, Sentiment Analysis, Tableau, Data Storytelling, Ranking & Performance Measurement 
            <br>
            <br>
              **Project Description:**

                <div style="margin-left: 45px; font-size: 15px;">
                  This project leverages advanced sentiment analysis on hundreds of thousands of Yelp reviews to uncover deeper emotional trends from customers. By applying a fine-tuned RoBERTa model on review data, it transforms traditional ratings into meaningful emotional insights. Additionally, the project calculates business rankings based on key metrics, providing businesses with valuable performance indicators and empowering customers to make better-informed decisions. The interactive dashboard allows businesses to monitor sentiment trends and customer satisfaction in real-time, while helping consumers compare businesses and select the best options based on customer feedback and calculated rankings.
                
                  <blockquote style="font-size: 15px; border-left: 5px solid #be3455;">
                    Data Source: <a href="https://business.yelp.com/data/resources/open-dataset/"  target="_blank">Yelp Open Dataset</a><br>
                    Reference Papers: <a href="https://arxiv.org/abs/1810.04805"  target="_blank">BERT</a> <span style="color: #939597;">|</span> <a href="https://arxiv.org/abs/1907.11692"  target="_blank">RoBERTa</a> <span style="color: #939597;">|</span> <a href="https://arxiv.org/abs/2005.00547"  target="_blank">GoEmotions</a><br>
                    Dashboard: <a href="https://public.tableau.com/views/BeyondYelpStarsBetterReviewInsightsforBusinessesCustomers/BeyondYelpStars?:language=en-US&:sid=&:redirect=auth&:display_count=n&:origin=viz_share_link"  target="_blank">Tableau Public</a> 
                    ‚ÄÑ <a href="https://ausername-asterisk.github.io/assets/files/Beyond_Yelp_Stars_Better_Review_Insights_for_Businesses_Customers.pdf" style="color: #97999B;"  target="_blank">[Link2]</a><br>
                        
                  </blockquote>
                </div>
            
            <br>      
            
            - **Lunar Lander Continuous Control with Proximal Policy Optimization and Generalized Advantage Estimation üöÄ**  <a id="featured-project1"></a>
              - Reinforcement Learning, Actor-Critic Methods, OpenAI's Gym & Gymnasium , PyTorch
            <br>
            <br>
              **Project Description:**

                <div style="margin-left: 45px; font-size: 15px;">
                  This project applies Proximal Policy Optimization (PPO) with Generalized Advantage Estimation (GAE) to continuous control in the LunarLanderContinuous v3 environment, improving both stability and performance. Experimental results show how hyperparameters such as GAE lambda, epsilon decay, and hidden layer size influence learning and reveal the trade-off between model complexity and efficiency. More broadly, the application of PPO with human feedback in large language models like ChatGPT has demonstrated its effectiveness in aligning outputs with user intent, leading to more accurate and reliable responses.           
                  
                  <blockquote style="font-size: 15px; border-left: 5px solid #be3455;">
                    Reference Papers: <a href="https://arxiv.org/abs/1707.06347"  target="_blank">PPO</a> <span style="color: #939597;">|</span> <a href="https://spinningup.openai.com/en/latest/algorithms/ppo.html"  target="_blank">PPO Implementation</a> <span style="color: #939597;">|</span> <a href="https://arxiv.org/abs/1506.02438"  target="_blank">GAE</a><br>
                    Technical Repor: <a href="https://ausername-asterisk.github.io/assets/files/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation.pdf"  target="_blank">Lunar Lander Continuous Control with PPO and GAE</a> 
                    ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation.pdf" style="color: #97999B;"  target="_blank">[Link2]</a><br>
                    Code: 
                        <a href="https://ausername-asterisk.github.io/assets/files/html/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation_Implementation_&_Training_GitHub.html"  target="_blank">  Implementation & Training.html </a> & 
                        <a href="https://ausername-asterisk.github.io/assets/files/html/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation_Results_&_Evaluation_GitHub.html"  target="_blank">  Results & Evaluation.html </a> 
                        ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation_Implementation_&_Training_GitHub.ipynb" style="color: #97999B;"  target="_blank"> [Link2a: ipynb </a>  <span style="color: #97999B;">&</span>
                        <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/42_Lunar_Lander_Continuous_Control_with_Proximal_Policy_Optimization_and_Generalized_Advantage_Estimation_Results_&_Evaluation_GitHub.ipynb" style="color: #97999B;"  target="_blank"> Link2b: ipynb]  </a>
                  </blockquote>
                </div>
            
            <br> 
            
            - **A DL Approach to Safeguard Coral Reefs: Detecting Crown-of-Thorn Starfish in Underwater Footage üåè**  <a id="featured-project3"></a>
              - Deep Neural Networks, Computer Vision, Object Detection, PyTorch, Data Augmentation, Model Evaluation  
            <br>
              **Project Description:**

                <div style="margin-left: 45px; font-size: 15px;">
                  The Great Barrier Reef faces major threats from climate change, pollution, and overpopulation of Crown-of-Thorn Starfish (COTS). To address this, we developed a real-time COTS detection system using the YOLOv11 model, trained on 23,501 underwater images. The model achieved a mean average precision (mAP@50) of 0.729 and an inference speed of 7.0 ms per image (143 FPS), making it highly effective for real-time detection. This solution improves detection efficiency and supports coral reef conservation.
                  
                  <blockquote style="font-size: 15px; border-left: 5px solid #be3455;">
                    Data Source: <a href="https://arxiv.org/abs/2111.14311" target="_blank">The CSIRO Crown-of-Thorn Starfish Detection Dataset</a><br>
                    Technical Report: <a href="https://ausername-asterisk.github.io/assets/files/20_A_Deep_Learning_Approach_to_Safeguard_Coral_Reefs_-_Detecting_Crown-of-Thorn_Starfish_in_Underwater_Footage.pdf"  target="_blank">Detecting Crown-of-Thorn Starfish in Underwater Footage</a> 
                    ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/20_A_Deep_Learning_Approach_to_Safeguard_Coral_Reefs_-_Detecting_Crown-of-Thorn_Starfish_in_Underwater_Footage.pdf" style="color: #97999B;"  target="_blank">[Link2]</a><br>
                    Code: 
                        <a href="https://ausername-asterisk.github.io/assets/files/html/21_Detecting_Crown_of_Thorn_Starfish_in_Underwater_Footage_EDA_&_Data_Augmentation_Github.html"  target="_blank">  EDA & Data Augmentation.html </a> & 
                        <a href="https://ausername-asterisk.github.io/assets/files/html/22_Detecting_Crown_of_Thorn_Starfish_in_Underwater_Footage_Training_&_Results_Github.html"  target="_blank">Training & Results.html </a> 
                        ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/21_Detecting_Crown_of_Thorn_Starfish_in_Underwater_Footage_EDA_%26_Data_Augmentation_Github.ipynb" style="color: #97999B;"  target="_blank"> [Link2a: ipynb </a>  <span style="color: #97999B;">&</span>
                        <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/22_Detecting_Crown_of_Thorn_Starfish_in_Underwater_Footage_Training_%26_Results_Github.ipynb" style="color: #97999B;"  target="_blank"> Link2b: ipynb]  </a>
                  </blockquote>
                </div>
            
            <br> 
            - **Assessing Avocado Pricing Dynamics Using Climate, Transportation Costs, and Economic Metrics in CA ü•ë**  
              - Machine Learning, EDA, Feature Engineering, Random Forest, Feature Importance, Cross-Validation  
            <br>
              **Project Description:**

                <div style="margin-left: 45px; font-size: 15px;">
                  This project investigates factors influencing avocado price fluctuations in California, focusing on climate, transportation costs, and economic data. Analysis of production, transport, and economic variables identifies key drivers of price changes. A Random Forest model achieved a training R¬≤ of 0.947 and testing R¬≤ of 0.798. Key factors include organic certification, lagged economic effects, and weather conditions, offering insights for improved price forecasting and supply chain management.
                  
                  <blockquote style="font-size: 15px; border-left: 5px solid #be3455;">
                    Data Source:  <a href="https://fred.stlouisfed.org"  target="_blank">Federal Reserve Data</a> <span style="color: #939597;">|</span> <a href="https://rp5.ru/Weather_in_the_world"  target="_blank">Weather In The World</a> <span style="color: #939597;">|</span> <a href="https://www.eia.gov/"  target="_blank">U.S. Energy Information Administration</a><br>
                    Technical Report:   <a href="https://ausername-asterisk.github.io/assets/files/10_Assessing_Avocado_Pricing_Dynamics_Utilizing_Climate__Transportation_Cost__and_Macroeconomic_Metrics_in_California.pdf"  target="_blank">Avocado Pricing and Influencing Factors in California</a>  
                    ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/10_Assessing_Avocado_Pricing_Dynamics_Utilizing_Climate__Transportation_Cost__and_Macroeconomic_Metrics_in_California.pdf"  style="color: #97999B;"  target="_blank">[Link2]</a><br>
                    Code:  
                        <a href="https://ausername-asterisk.github.io/assets/files/html/12_Assessing_Avocado_Pricing_Dynamics_Utilizing_Climate_Transportation_Cost_and_Macroeconomic_Metrics_in_California_Github.html"  target="_blank">EDA, Model Training, and Results.html </a> 
                        ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/12_Assessing_Avocado_Pricing_Dynamics_Utilizing_Climate_Transportation_Cost_and_Macroeconomic_Metrics_in_California_Github.ipynb"  style="color: #97999B;"  target="_blank"> [Link2: ipynb] </a>

                  </blockquote>
                </div>
            
            <br> 
            - **SVT Algorithm for Efficient Sparse Matrix Completion in a Book Recommender System üìö**  
              - Recommender Systems, Matrix Completion, Singular Value Thresholding, Collaborative Filtering  
            <br>
              **Project Description:**

                <div style="margin-left: 45px; font-size: 15px;">
                  This project implements the Singular Value Thresholding (SVT) algorithm for matrix completion, as described in the paper A Singular Value Thresholding Algorithm for Matrix Completion. The SVT algorithm efficiently recovers low-rank matrices from sparse data, using soft-thresholding on singular values. Tested on the GoodBooks dataset with 98.4% missing values, the algorithm achieved a 6.75% relative error after 150 iterations. The results confirm SVT's effectiveness in recovering matrices with high accuracy, making it a valuable tool for applications like recommendation systems and collaborative filtering.
                
                  <blockquote style="font-size: 15px; border-left: 5px solid #be3455;">
                    Data Source: <a href="https://www.kaggle.com/datasets/zygmunt/goodbooks-10k"  target="_blank">The Goodbooks Dataset</a><br>
                    Referenced Paper: <a href="https://arxiv.org/abs/0810.3286"  target="_blank">A Singular Value Thresholding Algorithm for Matrix Completion</a><br>
                    Code: 
                    <a href="https://ausername-asterisk.github.io/assets/files/html/2_SVT_Algorithm_for_Efficient_Sparse_Matrix_Recovery_and_Implementation_in_Python_Github.html"  target="_blank">Model Implementation and Results.html  </a> 
                    ‚ÄÑ <a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/2_SVT_Algorithm_for_Efficient_Sparse_Matrix_Recovery_and_Implementation_in_Python_Github.ipynb" style="color: #97999B;"  target="_blank"> [Link2: ipynb] </a>


                  </blockquote>
                </div>
                


                

  - title:  # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Work in Progress
        caption: 
        sub_title: 
        quote: >
        description: | # this will include new lines to allow paragraphs
        

                <div style="margin-left: 125px; font-size: 15px;"><a id="work_in_progress"></a>

                  <blockquote style="font-size: 15px; border-left: 5px solid #939597;">
                    Reinforcement Learning: 
                    <ul style="margin-left: 60px;">
                      <li>Learn to Make Good Sequences of Decisions Under Uncertainty</li>
                      <li><a href="https://arxiv.org/abs/1803.00710" target="_blank"> WIP: Replicating "Reinforcement Learning to Rank in E-Commerce Search Engine" </a></li>
                    </ul>
                    Probabilistic Machine Learning: 
                    <ul style="margin-left: 60px;">
                      <li><a href="https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd"  target="_blank">Probabilistic Machine Learning ‚Äì Philipp Hennig</a></li>
                    </ul>
                    5-Day Gen AI Intensive Course with Google Learn Guide: 
                    <ul style="margin-left: 60px;">
                      <li><a href="https://www.kaggle.com/learn-guide/5-day-genai"  target="_blank">5-Day Gen AI Intensive Course with Google Learn Guide ‚Äì Kaggle</a></li>
                    </ul>
                  </blockquote>
                </div>
                
        
  - title: Optimization # Title for the section
    layout: list # Type of content section (list/text)
    content:
    - layout: left
      title: Optimization
      caption: 
      sub_title: Georgia Tech
      quote: > 
        ". . . it is interesting to note that the original problem that started my research is still outstanding - namely the problem of planning or scheduling dynamically over time, particularly planning dynamically under uncertainty."
      description: |
        <div style="font-size: 14px;">
        This graduate-level optimization course covered essential concepts, models, and algorithms in depth. Beginning with foundational principles and mathematical underpinnings, the curriculum progressed through linear optimization techniques, including advanced topics such as the simplex method and duality theory. Subsequent modules explored nonlinear and convex conic optimization, broadening understanding beyond linear models. Additionally, the course included a study of integer optimization, providing insights into integrating integer decision variables into optimization frameworks.
        Practical skills were developed in formulating and solving complex optimization problems using Python-based tools. This experience enhanced proficiency in optimization theory, computational methods, and their applications in modern data analytics.


        <table style="border-collapse: collapse; width: 100%;">
          <thead>
            <tr style="border-bottom: 2px solid black;">
              <th style="padding: 8px; text-align: left;">Topic</th>
              <th style="padding: 8px; text-align: left;">Description</th>
              <th style="padding: 8px; text-align: left;">Implementation <br> (Private)</th>
            </tr>
          </thead>
          <tbody>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Convex & Nonconvex Optimization</td>
              <td style="padding: 8px;">Implementation of convex optimization using Newton's method and nonconvex optimization with Scipy's minimize function.</td>
              <td style="padding: 8px;">Python (numpy, scipy)</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Linear Programming</td>
              <td style="padding: 8px;">Solution of common manufacturing production and electric power network problems using linear programming optimization techniques.</td>
              <td style="padding: 8px;">Python (numpy, cvxpy)</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Solving Linear Program Using Basic Feasible Solutions</td>
              <td style="padding: 8px;">Identification of all possible basic solutions and determination of the optimal solution among them.</td>
              <td style="padding: 8px;">Python (numpy)</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Solving Linear Program Using Simplex Method </td>
              <td style="padding: 8px;">Implementation of the simplex method from scratch to solve linear programming problems.</td>
              <td style="padding: 8px;"><a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/4_Solving_Linear_Program_Using_Simplex_%26_Basic_Feasible_Solution_Methods_Github.ipynb">Simplex Method and Basic Feasible Solutions (numpy) ‚òÖ</a></td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Cutting Stock Problem With Column Generation </td>
              <td style="padding: 8px;">Solution of the cutting stock problem using column generation, applied to solve the pricing problem.</td>
              <td style="padding: 8px;">Python (numpy, cvxpy)</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px;">Location Optimization Using SOCP</td>
              <td style="padding: 8px;">Application of second-order cone programming to identify optimal locations for optimization problems.</td>
              <td style="padding: 8px;">Python (numpy, cvxpy)</td>
            </tr>
          </tbody>
        </table>
        </div>

        
        <br> <!-- Adds two empty lines -->
        
        **Additional Resources:**
        - [Convex Optimization ‚Äì Boyd and Vandenberghe   ‚òÖ](https://stanford.edu/~boyd/cvxbook/)
        - [ORF363 Computing and Optimization ](https://aaa.princeton.edu/orf363)
        - [ORF523 Convex and Conic Optimization](https://aaa.princeton.edu/orf523)
        
        <br> <!-- Adds two empty lines -->
        
        [**Return to Table of Contents**](#top)
        
  - title: Machine Learning # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Machine Learning
        caption: 
        sub_title: Georgia Tech
        quote: > 
          "In God we trust, all others bring data."
        description: | # this will include new lines to allow paragraphs
          <div style="font-size: 14px;">
          This graduate-level machine learning course delved deeply into essential methodologies, theories, and algorithms across various domains. Beginning with fundamental concepts in clustering, dimensionality reduction, and statistical modeling, the curriculum progressed to advanced techniques such as Gaussian mixture models, support vector machines (SVM), and ensemble methods like AdaBoost and random forests. Practical application was a key focus, with hands-on projects using Python for algorithm implementation and analysis of real-world datasets. The course provided a thorough understanding of machine learning principles, equipping participants with the skills to tackle intricate analytical problems, optimize model performance, and derive meaningful insights from data.
  
          <table style="border-collapse: collapse; width: 100%;">
            <thead>
              <tr style="border-bottom: 2px solid black; text-align: center;">
                <th style="padding: 8px;">Topic</th>
                <th style="padding: 8px;">Description</th>
                <th style="padding: 8px;">Implementation <br> (Private)</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Clustering and K-means</td>
                <td style="padding: 8px;">Image Compression using K means Algorithm</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Clustering and K-means</td>
                <td style="padding: 8px;">Evaluation of K means and K median Clustering on MNIST Dataset</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Spectral Clustering</td>
                <td style="padding: 8px;">Political Blogosphere Analysis Using Spectral Clustering <a href="https://arxiv.org/abs/0711.0189">(Spectral Clustering, Ulrike von Luxburg)</a></td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Dimensionality Reduction and PCA</td>
                <td style="padding: 8px;">Eigenface Generation and Analysis using PCA on the Olivetti Faces Dataset</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Nonlinear Dimensionality Reduction </td>
                <td style="padding: 8px;">ISOMAP Algorithm Implementation and Visualization for Facial Image Analysis <a href="https://www.science.org/doi/10.1126/science.290.5500.2319">(ISOMAP Paper)</a></td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Density Estimation</td>
                <td style="padding: 8px;">Analyzing Brain Structure and Categorical Labels Data Distribution</td>
                <td style="padding: 8px;">Python (matplotlib, seaborn)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Gaussian Mixture Model and EM Algorithm</td>
                <td style="padding: 8px;">Image Classification with Gaussian Mixture Models using EM</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Classification</td>
                <td style="padding: 8px;">Comparing ML Classifiers: Model Performance & Decision Boundaries <a href="https://scikit-learn.org/stable/supervised_learning.html">(sklearn Documentation)</a></td>
                <td style="padding: 8px;"><a href="https://github.com/Ausername-Asterisk/Ausername-Asterisk.github.io/blob/main/assets/files/8_Comparing_ML_Classifiers_Model_Performance_%26_Decision_Boundaries_Github.ipynb"> Comparing ML Classifiers: Model Performance & Decision Boundaries ‚òÖ</a></td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Anomaly Detection</td>
                <td style="padding: 8px;">CUSUM for Distribution Shift Detection</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr id="ML-project" style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Feature Selection & Random Forest</td>
                <td style="padding: 8px;">Fine Tuning Machine Learning Models for CART Random Forest and One Class SVM <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">(Random Forests, Leo Breiman)</a></td>
                <td style="padding: 8px;">Python (numpy, sklearn)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Nonlinear Regression</td>
                <td style="padding: 8px;">Locally Weighted Linear Regression with Bias Variance Tradeoff and Hyperparameter Fine Tuning</td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
            </tbody>
          </table>
          </div>
    
            
            <br> <!-- Adds two empty lines -->
            
            **Books:**
            - [ The Elements of Statistical Learning  ‚òÖ](https://www.google.com/books/edition/The_Elements_of_Statistical_Learning/yPfZBwAAQBAJ?hl=en)
            - [ A Mathematical Introduction to Data Science by Yuan Yao  ‚òÖ](https://www.math.pku.edu.cn/teachers/yaoy/reference/book05.pdf)
            - [Pattern Recognition and Machine Learning](https://www.google.com/books/edition/Pattern_Recognition_and_Machine_Learning/kOXDtAEACAAJ?hl=en)
            - [Foundations of Machine Learning](https://www.google.com/books/edition/Foundations_of_Machine_Learning_second_e/V2B9DwAAQBAJ?hl=en)
            - [An Introduction to Statistical Learning](https://www.statlearning.com/)
            - [Collaborative filtering  (recommender systems)](https://en.wikipedia.org/wiki/Collaborative_filtering)
            - [Fairness and machine learning](https://fairmlbook.org/)
            
            <br> <!-- Adds two empty lines -->

             **Additional Resources:**
            - [ Intuition for the Algorithms of Machine Learning ‚Äî Cynthia Rudin  ‚òÖ](https://users.cs.duke.edu/~cynthia/teaching.html)
            - [ Statistical Machine Learning ‚Äî Ulrike von Luxburg  ‚òÖ](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC)
            - [Mathematics for Machine Learning ‚Äî Ulrike von Luxburg](https://www.youtube.com/playlist?list=PL05umP7R6ij1a6KdEy8PVE9zoCv6SlHRS)
            - [Statistical Learning with Python ‚Äî Trevor Hastie, Robert Tibshirani](https://www.youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ)
            - [CS229: Machine Learning ‚Äî Andrew Ng](https://cs229.stanford.edu/)   
            
            <br> <!-- Adds two empty lines -->
        
            [**Return to Table of Contents**](#top)
            
  - title: High-Dimensional Statistics # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: High-Dimensional Statistics
        caption: 
        sub_title: Georgia Tech
        quote: >
          "It is vain to do with more what can be done with less." 
        description: | # this will include new lines to allow paragraphs
          <div style="font-size: 14px;">
          This graduate-level course in High-Dimensional Statistics is designed to equip professionals with essential skills in feature extraction and dimensionality reduction in statistical machine learning. The curriculum focuses on key topics such as functional data analysis, advanced image processing techniques, multilinear algebra, tensor analysis, and advanced regularization techniques for handling complex datasets. These foundational areas provide vital tools for effectively understanding and interpreting data, improving the extraction of meaningful features, and simplifying data analysis. Understanding these techniques prepares professionals to address challenges in image analysis, optimize predictive models to prevent overfitting, and gain useful insights across various data-driven fields.

          <table style="border-collapse: collapse; width: 100%;">
            <thead>
              <tr style="border-bottom: 2px solid black; text-align: center;">
                <th style="padding: 8px;">Topic</th>
                <th style="padding: 8px;">Additional Readings</th>
                <th style="padding: 8px;">Implementation <br> (Private)</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Linear Regression <br> Splines <br> BSplines <br> Smoothing Splines <br> Kernel Smoothers <br> FPCA</td>
                <td style="padding: 8px;">
                  <a href="https://www.google.com/books/edition/The_Elements_of_Statistical_Learning/yPfZBwAAQBAJ?hl=en">1. The Elements of Statistical Learning Pages 43-52, 139-161, 186-208</a> <br>
                  <a href="https://www.researchgate.net/publication/4741968_Functional_Data_Analysis_for_Sparse_Longitudinal_Data">2. Functional Data Analysis for Sparse Longitudinal Data</a>
                </td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr id="HDDA-project1" style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Image Filtering and Convolution <br> Image Transformation & Edge Detection <br> Image segmentation</td>
                <td style="padding: 8px;">
                  <a href="https://www.google.com/books/edition/A_Concise_Introduction_to_Image_Processi/fp7SBQAAQBAJ?hl=en">1. A Concise Introduction to Image Processing Using C++ Chapters 2, 3, 4</a>
                </td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Tensor Preliminaries <br> Tensor Decomposition <br> Tensor Applications I <br> Tensor Applications II <br> Tensor Applications III</td>
                <td style="padding: 8px;">
                  <a href="https://www.jstor.org/stable/25662308?seq=1#metadata_info_tab_contents">1. Tensor Decompositions and Applications 455-480</a> <br>
                  <a href="https://arxiv.org/abs/1807.10278">2. Structured Point Cloud Data Analysis via Regularized Tensor Regression for Process Modeling and Optimization</a> <br>
                  <a href="https://arxiv.org/abs/1706.03423">3. Image-Based Prognostics Using Penalized Tensor Regression</a> <br>
                  <a href="https://www.researchgate.net/publication/228553771_Tensor_decompositions_for_feature_extraction_and_classification_of_high_dimensional_datasets">4. Tensor decompositions for feature extraction and classification of high dimensional datasets ‚òÖ</a>
                </td>
                <td style="padding: 8px;">
                    Python (numpy) 
                </td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Optimization: First order methods <br> Optimization: Second order methods</td>
                <td style="padding: 8px;">
                  <a href="https://stanford.edu/~boyd/cvxbook/">1. Convex Optimization Pages 1-11, 21-35, 67-79, 457-475 and 484-487</a> <br>
                  <a href="https://www.google.com/books/edition/Numerical_Methods_for_Least_Squares_Prob/aQD1LLYz6tkC?hl=en">2. Numerical Methods for Least Squares Problems Ch 9</a>
                </td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Proximal Gradient Descent <br> Coordinate Descent <br> ALM and ADMM</td>
                <td style="padding: 8px;">
                  <a href="https://www.google.com/books/edition/Optimization_for_Machine_Learning/JPQx7s2L1A8C?hl=en">1. Optimization for Machine Learning Page 27-34</a> <br>
                  <a href="https://www.google.com/books/edition/Distributed_Optimization_and_Statistical/8MjgLpJ0_4YC?hl=en">2. Distributed Optimization and Statistical Learning Via the Alternating Direction Method of Multipliers Page 1-24</a>
                </td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Ridge Regression & LASSO <br> NNG <br> Adaptive LASSO <br> Grouped LASSO <br> Elastic Net</td>
                <td style="padding: 8px;">
                  <a href="https://www.google.com/books/edition/The_Elements_of_Statistical_Learning/yPfZBwAAQBAJ?hl=en">1. The Elements of Statistical Learning Page 61-73</a> <br>
                  <a href="https://www.researchgate.net/publication/4742238_The_adaptive_LASSO_ad_its_oracle_properties">2. The adaptive LASSO and its oracle properties</a> <br>
                  <a href="https://www.researchgate.net/publication/243776325_Better_Subset_Regression_Using_the_Nonnegative_Garrote">3. Better Subset Regression Using the Nonnegative Garrote</a> <br>
                  <a href="https://www.researchgate.net/publication/4993325_Model_Selection_and_Estimation_in_Regression_With_Grouped_Variables">4. Model Selection and Estimation in Regression With Grouped Variables</a> <br>
                  <a href="https://www.researchgate.net/publication/227604843_Zou_H_Hastie_T_Regularization_and_variable_selection_via_the_elastic_net_J_R_Statist_Soc_B_2005672301-20">5. Regularization and variable selection via the elastic net</a>
                </td>
                <td style="padding: 8px;">Python (numpy)</td>
              </tr>
              <tr id="HDDA-project2" style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px;">Compressive Sensing <br> Matrix Completion <br> Robust PCA <br> Smooth-Sparse Decomposition <br> RKHS Ridge Kernel Regression</td>
                <td style="padding: 8px;">
                  <a href="https://www.researchgate.net/publication/3322018_Wakin_MB_An_introduction_to_compressive_sampling_IEEE_Signal_Process_Mag_252_21-30">1. An introduction to compressive sampling</a> <br>
                  <a href="https://arxiv.org/abs/0810.3286">2. A Singular Value Thresholding Algorithm for Matrix Completion ‚òÖ</a> <br>
                  <a href="https://arxiv.org/abs/0805.4471">3. Exact Matrix Completion via Convex Optimization</a> <br>
                  <a href="https://www.researchgate.net/publication/221618324_Robust_Principal_Component_Analysis_Exact_Recovery_of_Corrupted_Low-Rank_Matrices_via_Convex_Optimization">4. Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization</a> <br>
                  <a href="https://arxiv.org/abs/0912.3599">5. Robust Principal Component Analysis?</a> <br>
                  <a href="https://www.gatsby.ucl.ac.uk/~gretton/coursefiles/lecture4_introToRKHS.pdf">6. Introduction to RKHS, and some simple kernel algorithms</a> <br>
                  <a href="https://www.researchgate.net/publication/283520589_Anomaly_Detection_in_Images_with_Smooth_Background_Via_Smooth-Sparse_Decomposition">7. Anomaly Detection in Images with Smooth Background Via Smooth-Sparse Decomposition</a>
                </td>
                <td style="padding: 8px;">
                    Python (numpy) 
                </td>
              </tr>
            </tbody>
          </table>
          </div>
  
              
            <br> <!-- Adds two empty lines -->
            
            **Additional Resources:**
            - [ High-Dimensional Data Analysis with Low-Dimensional Models ‚Äî John Wright, Yi Ma  ‚òÖ](https://book-wright-ma.github.io/)
            - [Convex Optimization ‚Äì Boyd and Vandenberghe  ](https://stanford.edu/~boyd/cvxbook/)
        
            <br> <!-- Adds two empty lines -->
        
            [**Return to Table of Contents**](#top)
            
  - title: Deep Learning # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Deep Learning 
        caption: 
        sub_title: Georgia Tech
        quote: > 
            "Attention is all you need." 
           
        description: | # this will include new lines to allow paragraphs
            <div style="font-size: 14px;">
            Deep learning, a specialized branch of machine learning, focuses on extracting intricate hierarchical representations from raw data. Central to this field is artificial neural networks, which have revolutionized data processing across various domains such as image analysis, natural language processing, and decision-making tasks. This course delves into fundamental principles, mathematical foundations, and practical implementation of deep learning. Topics include optimization techniques like gradient descent and backpropagation, foundational neural network modules such as linear and convolutional layers, and advanced architectures like recurrent neural networks and convolutional neural networks. Through hands-on programming assignments using PyTorch, participants will learn to construct and optimize neural networks, apply them to real-world applications, choose appropriate models for diverse problems, and understand ongoing research challenges in the field.

            <table style="border-collapse: collapse; width: 100%;">
              <thead>
                <tr style="border-bottom: 2px solid black;">
                  <th style="padding: 8px; text-align: left;">Topic</th>
                  <th style="padding: 8px; text-align: left;">Additional Readings</th>
                  <th style="padding: 8px; text-align: left;">Implementation <br> (Private)</th>
                </tr>
              </thead>
              <tbody>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">Linear Classifiers and Gradient Descent</td>
                  <td style="padding: 8px;">
                    <a href="https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en">1. Deep Learning Ch 2 - 5</a><br>
                    <a href="https://www.nature.com/articles/nature14539">2. Deep learning</a><br>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?reload=true&arnumber=1056774">3. DShannon, 1956</a>
                  </td>
                  <td style="padding: 8px;">Python (numpy)</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Neural Networks</td>
                  <td style="padding: 8px;">
                    <a href="https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en">1. Deep Learning Ch 6</a><br>
                    <a href="https://arxiv.org/abs/1802.01528">2. The Matrix Calculus You Need For Deep Learning ‚òÖ</a><br>
                    <a href="https://arxiv.org/abs/1502.05767">3. Automatic differentiation in machine learning: a survey</a>
                  </td>
                  <td style="padding: 8px;">Python (numpy)</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Optimization of Deep Neural Networks</td>
                  <td style="padding: 8px;">
                    <a href="https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en">1. Deep Learning Ch 7 - 8</a><br>
                    <a href="https://arxiv.org/abs/1803.09820">2. A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay ‚òÖ</a>
                  </td>
                  <td style="padding: 8px;">Python (numpy)</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">
                     Data Wrangling<br>
                     Convolution and Pooling Layers<br>
                    Convolutional Neural Network Architectures
                  </td>
                  <td style="padding: 8px;">
                    <a href="https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en">1. Deep Learning Ch 9</a><br>
                    <a href="https://hadrienj.github.io/posts/Preprocessing-for-deep-learning/">2. Preprocessing for deep learning: from covariance matrix to image whitening</a><br>
                    <a href="https://cs231n.github.io/neural-networks-2/">3. Convolutional Neural Networks for Visual Recognition</a>
                  </td>
                  <td style="padding: 8px;">Python (numpy) & PyTorch</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">
                     Visualization<br>
                    PyTorch and Scalable Training<br>
                    Advanced Computer Vision Architectures<br>
                  </td>
                  <td style="padding: 8px;">
                    <a href="https://arxiv.org/abs/1506.06579">1. Understanding Neural Networks Through Deep Visualization</a><br>
                    <a href="https://arxiv.org/abs/1610.02391">2. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a><br>
                    <a href="https://arxiv.org/abs/1605.06211">3. Fully Convolutional Networks for Semantic Segmentation</a>
                  </td>
                  <td style="padding: 8px;">Python (numpy) & Captum</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">
                     Bias and Fairness
                  </td>
                  <td style="padding: 8px;">
                    <a href="https://fairmlbook.org/">1. Fairness and machine learning</a><br>
                    <a href="https://gdpr.eu/what-is-gdpr/">2. General Data Protection Regulation (GDPR) </a><br>
                    <a href="https://oag.ca.gov/privacy/ccpa">3. California Consumer Privacy Act (CCPA)</a><br>
                    <a href="https://www.science.org/doi/10.1126/sciadv.aao5580">4. The accuracy, fairness, and limits of predicting recidivism</a>
                  </td>
                  <td style="padding: 8px;"> <a href="https://www.scu.edu/ethics/ethics-resources/a-framework-for-ethical-decision-making/">Markkula Center for Applied Ethics </a><br>  </td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">
                     Introduction to Structured Representations<br>
                     Language Models
                  </td>
                  <td style="padding: 8px;">
                    <a href="https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en">1. Deep Learning Ch 10</a>
                  </td>
                  <td style="padding: 8px;">PyTorch</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Embeddings</td>
                  <td style="padding: 8px;">
                    <a href="https://arxiv.org/abs/1301.3781">1. Efficient Estimation of Word Representations in Vector Space</a><br>
                    <a href="https://arxiv.org/abs/1709.03856">2. StarSpace: Embed All The Things!</a><br>
                    <a href="https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">3. Word2Vec Tutorial</a>
                  </td>
                  <td style="padding: 8px;">PyTorch</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Neural Attention Models</td>
                  <td style="padding: 8px;">
                    <a href="https://arxiv.org/abs/1706.03762">1. Attention Is All You Need ‚òÖ</a><br>
                    <a href="https://arxiv.org/abs/1810.04805">2. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a><br>
                    <a href="https://jalammar.github.io/illustrated-transformer/">3. The Illustrated Transformer</a><br>
                    <a href="https://arxiv.org/abs/1503.02531">4. Distilling the Knowledge in a Neural Network ‚òÖ</a><br>
                  </td>
                  <td style="padding: 8px;">PyTorch</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;">
                     Neural Machine Translation<br>
                     Automated Speech Recognition (ASR)
                  </td>
                  <td style="padding: 8px;">
                      <a href="https://arxiv.org/abs/1409.3215">1. Sequence to Sequence Learning with Neural Networks</a><br>
                  </td>
                  <td style="padding: 8px;">PyTorch</td>
                </tr>
                <tr id="DL-project" style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Deep Reinforcement Learning</td>
                  <td style="padding: 8px;">
                      <a href="https://spinningup.openai.com/en/latest/index.html">1. OpenAI Spinning Up in Deep RL</a><br>
                      <a href="https://arxiv.org/abs/1707.06203">2. Imagination-Augmented Agents for Deep Reinforcement Learning</a><br>
                  </td>
                  <td style="padding: 8px;"> - </td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Unsupervised and Semi-Supervised Learning</td>
                  <td style="padding: 8px;">
                    <a href="https://arxiv.org/abs/1605.06211">1. Fully Convolutional Networks for Semantic Segmentation</a>
                  </td>
                  <td style="padding: 8px;"> - </td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                  <td style="padding: 8px;"> Generative Models</td>
                  <td style="padding: 8px;">
                    <a href="https://arxiv.org/abs/1606.05908">1. Tutorial on Variational Autoencoders</a><br>
                    <a href="https://arxiv.org/abs/1701.00160">2. Generative Adversarial Networks</a>
                  </td>
                  <td style="padding: 8px;"> - </td>
                </tr>
              </tbody>
            </table>
            </div>



            <br> <!-- Adds two empty lines -->
          

            
            **Books:**
            - [Deep Learning ‚Äì Ian Goodfellow, Yoshua Bengio, Aaron Courville ‚òÖ ](https://www.google.com/books/edition/Deep_Learning/Np9SDQAAQBAJ?hl=en)
            - [Dive into Deep Learning  ‚òÖ ](https://d2l.ai/)
            - [Implementations of deep learning papers  ](https://github.com/labmlai/annotated_deep_learning_paper_implementations)
            
            <br> <!-- Adds two empty lines -->
            
            **Additional Resources:**
            - [CS231n Deep Learning for Computer Vision ‚òÖ](https://cs231n.stanford.edu/)
            - [CS230 Deep Learning ‚Äì Andrew Ng ‚òÖ](https://cs230.stanford.edu/)
            - [Deep Learning for Computer Vision](https://web.eecs.umich.edu/~justincj/teaching/eecs498/)
            - [Deep Learning ‚Äî Andreas Geiger ](https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/autonomous-vision/lectures/deep-learning/)
            - [CS 7643 - Deep Learning Notes ](https://lowyx.com/posts/gt-dl-notes/)
            - [Natural Language Processing with Deep Learning ](https://web.stanford.edu/class/cs224n/)
            - [Math for Deep Learning ‚Äî Andreas Geiger  ](https://www.youtube.com/playlist?list=PL05umP7R6ij0bo4UtMdzEJ6TiLOqj4ZCm)
            - [Neural Networks: Zero to Hero  ](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ)
            - [Deeplake Datasets ](https://datasets.activeloop.ai/docs/ml/datasets/)     
            
            <br> <!-- Adds two empty lines -->
        
            [**Return to Table of Contents**](#top)

            
  - title: Reinforcement Learning # Title for the section
    layout: list # Type of content section (list/text)
    content:
      - layout: left
        title: Reinforcement Learning # Title for the section
        caption: Work in Progress
        sub_title: Georgia Tech
        quote: > 
            "The future is independent of the past given the present" 
           
        description: | # this will include new lines to allow paragraphs
            <div style="font-size: 14px;">
            Reinforcement Learning and Decision Making examines how computational agents develop sequential decision-making policies through trial-and-error interactions with their environments, formalized as Markov decision processes (MDPs) and partially observable MDPs (POMDPs). Topics include dynamic programming and value-based methods (Bellman equations, policy and value iteration), temporal-difference algorithms (TD(0), Q-learning, SARSA) with convergence guarantees, function approximation for generalization, exploration strategies (Œµ-greedy, upper-confidence bounds, intrinsic motivation), policy-based and actor-critic frameworks, and multi-agent/game-theoretic models (stochastic and repeated games, decentralized POMDPs). Implementation using standard RL libraries supports the evaluation of these algorithms, design of representation and exploration schemes, and management of partial observability and multi-agent coordination, preparing participants for real-world applications and research.
            
            <table style="border-collapse: collapse; width: 100%;">
              <thead>
                <tr style="border-bottom: 2px solid black;">
                  <th style="padding: 8px; text-align: left;">Topic</th>
                  <th style="padding: 8px; text-align: left;">Additional Readings</th>
                  <th style="padding: 8px; text-align: left;">Implementation <br> (Private)</th>
                </tr>
              </thead>
              <tbody>
                <tr><td style="padding: 8px;">Markov Reward Process (MRP)  <br> Markov Decision Process (MDP) </td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Monte Carlo Policy Evaluation  <br> Temporal Difference (TD) </td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Value Iteration<br>Policy Iteration </td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">SARSA <br> Q-Learning </td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Convergence <br> Generalization <br> Partially Observable MDPs</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Function Approximation  <br> Deep Reinforcement Learning</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Actor-Critic Algorithm <br> REINFORCE <br>Proximal Policy Optimization (PPO)</td><td style="padding: 8px;"><a href="https://arxiv.org/abs/1707.06347">1. Proximal Policy Optimization Algorithms</a><br>
                    <a href="https://arxiv.org/abs/2005.12729">2. Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO</a></td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Offline RL <br> Direct Preference Optimization (DPO)</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Exploring Exploration</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Game Theory <br> Multi-Agent RL</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
                <tr><td style="padding: 8px;">Value Alignment</td><td style="padding: 8px;">Work in Progress</td><td style="padding: 8px;">Work in Progress</td></tr>
              </tbody>
            </table>
            
            </div>



            <br> <!-- Adds two empty lines -->
          

            
            **Books:**
            - [Reinforcement Learning: An Introduction ‚Äì Richard S. Sutton, Andrew G. Barto ‚òÖ ](http://www.incompleteideas.net/book/the-book.html)
            - [Multi-Agent Reinforcement Learning: Foundations and Modern Approaches](https://www.marl-book.com/)
            
            <br> <!-- Adds two empty lines -->
            
            **Additional Resources:**
            - [Reinforcement Learning ‚Äì Emma Brunskill  ‚òÖ](https://www.youtube.com/playlist?list=PLoROMvodv4rN4wG6Nk6sNpTEbuOSosZdX)  \|  [Lectures](https://web.stanford.edu/class/cs234/) 
            - [Reinforcement Learning ‚Äì David Silver  ‚òÖ](https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ)  \|  [Lectures](https://davidstarsilver.wordpress.com/teaching/) 
            - [OpenAI Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/index.html) 
            - [Gymnasium Documentation](https://gymnasium.farama.org/) 

              
            
            <br> <!-- Adds two empty lines -->
        
            [**Return to Table of Contents**](#top)

            
  - title: Supplementary Information
    layout: text
    content: | # this will include new lines to allow paragraphs
      The supplementary materials provide additional information on the topics of AI, Statistics, Machine Learning, and Data Science.
      - [AI-Expert-Roadmap ‚òÖ](https://github.com/AMAI-GmbH/AI-Expert-Roadmap)
      - [Hugging Face ü§ó - Models ‚òÖ](https://huggingface.co/models)
      - [Hugging Face ü§ó - LLM Leaderboard ‚òÖ](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)
      - [Trustworthy Online Controlled Experiments (A/B Testing) ‚òÖ](https://www.google.com/books/edition/Trustworthy_Online_Controlled_Experiment/NHjQDwAAQBAJ?hl=en)
      - [Hypothesis Test Selection Flowchart ‚òÖ](https://ausername-asterisk.github.io/assets/images/flowchart_choosing_a_test_by_the_data.jpg)
      - [Kaggle Competition ](https://www.kaggle.com/competitions)
      - [StrataScratch ](https://www.stratascratch.com/)
      - [Github Ranking ](https://github.com/EvanLi/Github-Ranking)
      - [Docker Hub ](https://hub.docker.com/)
      - [Papers With Code ](https://paperswithcode.com/)
      - [PEP 8 ‚Äì Style Guide for Python Code](https://peps.python.org/pep-0008/)
      - [SQL Style Guide](https://www.sqlstyle.guide/)
      - [Lil'Log](https://lilianweng.github.io/)
      
      <br> <!-- Adds two empty lines -->
            
      Information is Beautiful:
      - [Information is Beautiful Awards ‚òÖ](https://www.informationisbeautifulawards.com/showcase?page=1&type=awards) 
      - [Design Resources for Developers ‚òÖ](https://github.com/bradtraversy/design-resources-for-developers) 
      - [Awwwards - Sites of the Month ‚òÖ](https://www.awwwards.com/websites/sites_of_the_month/) 
      - [Tableau - Viz of the Day ‚òÖ](https://public.tableau.com/app/discover/viz-of-the-day) 
      - [D3 Gallery](https://d3js.org/) 
      - [Gapminder](https://www.gapminder.org/) 
      - [Eloquent JavaScript](https://eloquentjavascript.net/)
      - [Guide to Information Graphics](https://www.google.com/books/edition/The_Wall_Street_Journal_Guide_to_Informa/Q4a3EAAAQBAJ?hl=en)
      - [Beautiful Evidence](https://www.google.com/books/edition/Beautiful_Evidence/jAcBngEACAAJ?hl=en)  <span style="color: #477eca;">|</span>    [Now You See it](https://www.google.com/books/edition/Now_You_See_it/xw_qOwAACAAJ?hl=en)
      - [Adobe Color](https://color.adobe.com/trends) <span style="color: #477eca;">|</span>   [ColorBrewer](https://colorbrewer2.org/)
      - [ArchDaily](https://www.archdaily.com/)

      <br> <!-- Adds two empty lines -->
  
      Courses:
      - [Generalized Linear Models (Survival Model) ‚òÖ](https://grodri.github.io/glms/notes/)
      - [Machine Learning & Causal Inference](https://www.youtube.com/playlist?list=PLxq_lXOUlvQAoWZEqhRqHNezS30lI49G-)
      - [Probabilistic Machine Learning ](https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd)
      - [Algorithms and Data Structures using Python ](https://runestone.academy/ns/books/published/pythonds3/index.html)

      
  - title: Future Update
    layout: text
    content: | # this will include new lines to allow paragraphs
      This repository is continuously updated as I progress through my studies and hands-on learning. I am currently deepening my knowledge in state-of-the-art AI development, particularly in deep learning, reinforcement learning, and large language models, and exploring their real-world applications. I‚Äôm also focusing on expanding my expertise in product development and experimental design to bridge the gap between statistical analysis, user experience, and practical deployment in business settings.

      In the future, I plan to enhance my skills in web design and data visualization using HTML, CSS, JavaScript, and libraries like D3.js. Additionally, I look forward to developing expertise in cloud computing and modern technologies such as Spark, Docker, Scala, Databricks, AWS, and GCP. üë®‚ÄçüöÄ üåü
      
      <br>


      ![alt](assets/images/alt.jpeg "alt")    
      
      <br>
      
# Footer _includes/footer.html
footer_show_references: true
references_title: Life, I'm lovin' it. 

# Build settings
remote_theme: Ausername-Asterisk/modern-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag
